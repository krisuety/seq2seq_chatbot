{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"ChatBotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SNS보면 나만 빼고 다 행복해보여</td>\n",
       "      <td>자랑하는 자리니까요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>가끔 궁금해</td>\n",
       "      <td>그 사람도 그럴 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>가끔 뭐하는지 궁금해</td>\n",
       "      <td>그 사람도 그럴 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>가끔은 혼자인게 좋다</td>\n",
       "      <td>혼자를 즐기세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>가난한 자의 설움</td>\n",
       "      <td>돈은 다시 들어올 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>가만 있어도 땀난다</td>\n",
       "      <td>땀을 식혀주세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>가상화폐 쫄딱 망함</td>\n",
       "      <td>어서 잊고 새출발 하세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>가스불 켜고 나갔어</td>\n",
       "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>가스불 켜놓고 나온거 같아</td>\n",
       "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>가스비 너무 많이 나왔다.</td>\n",
       "      <td>다음 달에는 더 절약해봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>가스비 비싼데 감기 걸리겠어</td>\n",
       "      <td>따뜻하게 사세요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>가스비 장난 아님</td>\n",
       "      <td>다음 달에는 더 절약해봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>가장 확실한 건 뭘까?</td>\n",
       "      <td>가장 확실한 시간은 오늘이에요. 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>가족 여행 가기로 했어</td>\n",
       "      <td>온 가족이 모두 마음에 드는 곳으로 가보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>가족 여행 고고</td>\n",
       "      <td>온 가족이 모두 마음에 드는 곳으로 가보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>가족 여행 어디로 가지?</td>\n",
       "      <td>온 가족이 모두 마음에 드는 곳으로 가보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>가족 있어?</td>\n",
       "      <td>저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>가족관계 알려 줘</td>\n",
       "      <td>저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>가족끼리 여행간다.</td>\n",
       "      <td>더 가까워질 기회가 되겠네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>가족들 보고 싶어</td>\n",
       "      <td>저도요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11793</th>\n",
       "      <td>호감을 표현하는 방법</td>\n",
       "      <td>취미와 성향 등이 같음을 어필해보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11794</th>\n",
       "      <td>혼인신고 아직 안 했는데 이혼해도 될까</td>\n",
       "      <td>결심은 빠르면 빠를수록 좋아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11795</th>\n",
       "      <td>혼인신고 하러 왔어</td>\n",
       "      <td>법적 부부가 된 걸 축하해요!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11796</th>\n",
       "      <td>혼인신고하니까 마음이 이상해</td>\n",
       "      <td>법적 부부가 된 걸 축하해요!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11797</th>\n",
       "      <td>혼자 노력하는 연애인 거 같아</td>\n",
       "      <td>힘들면 잠시 놓는것도 방법이에요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>혼자 썸타는 기분이야.</td>\n",
       "      <td>직접적이든 간접적이든 의사를 확실히 밝혀보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11799</th>\n",
       "      <td>혼자 좋아하는 것 같아</td>\n",
       "      <td>외로운 상태인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11800</th>\n",
       "      <td>나만 좋아하는 것 같아</td>\n",
       "      <td>적극적으로 꼬셔보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11801</th>\n",
       "      <td>혼자 좋아하는 이야기 들어 볼래요?</td>\n",
       "      <td>손수건 준비할게요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11802</th>\n",
       "      <td>혼자 좋아하는 이야기.</td>\n",
       "      <td>힘들겠지만 제게 말해보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11803</th>\n",
       "      <td>혼자 좋아하는게 이렇게 힘든 적은 처음이에요.</td>\n",
       "      <td>사랑은 더 잘하게 되지 않고 다시 영에서 시작하니 모두 처음이겠죠.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11804</th>\n",
       "      <td>혼자가 편하다는 짝남에게 먼저 대쉬해버림.</td>\n",
       "      <td>거절의 뜻은 아니었나요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11805</th>\n",
       "      <td>혼자가 편하다는 짝녀에게 들이댔음.</td>\n",
       "      <td>혼자가 편하다는 것이 거절의 뜻은 아니었을까요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.</td>\n",
       "      <td>맘고생 많았어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>화이트데이에 고백할까요?</td>\n",
       "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11808</th>\n",
       "      <td>화장 안했는데 썸남이 영통 걸었어. 어떡해?</td>\n",
       "      <td>화장실 불빛으로 좀 멀리 가리고 해보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11809</th>\n",
       "      <td>확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?</td>\n",
       "      <td>그 사람을 위해서는 그러면 안돼요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11810</th>\n",
       "      <td>확실히 좋아하는 데도 관심 있는거 티 안내려고 선톡 안하고 일부러 늦게 보내고 그러...</td>\n",
       "      <td>많이 있어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11811</th>\n",
       "      <td>홧김에 짝남한테 고백했다.</td>\n",
       "      <td>화끈하시네요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11812</th>\n",
       "      <td>회사 짝남 오빠 게임 초대 톡 옴.</td>\n",
       "      <td>설렜을텐데 아쉽겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n",
       "      <td>사랑하기 힘든 관계인가봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n",
       "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
       "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>후회 없이 사랑하고 싶어</td>\n",
       "      <td>진심으로 다가가 보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Q  \\\n",
       "0                                                 12시 땡!   \n",
       "1                                            1지망 학교 떨어졌어   \n",
       "2                                           3박4일 놀러가고 싶다   \n",
       "3                                        3박4일 정도 놀러가고 싶다   \n",
       "4                                                PPL 심하네   \n",
       "5                                              SD카드 망가졌어   \n",
       "6                                                SD카드 안돼   \n",
       "7                                         SNS 맞팔 왜 안하지ㅠㅠ   \n",
       "8                                SNS 시간낭비인 거 아는데 매일 하는 중   \n",
       "9                                      SNS 시간낭비인데 자꾸 보게됨   \n",
       "10                                   SNS보면 나만 빼고 다 행복해보여   \n",
       "11                                                가끔 궁금해   \n",
       "12                                           가끔 뭐하는지 궁금해   \n",
       "13                                           가끔은 혼자인게 좋다   \n",
       "14                                             가난한 자의 설움   \n",
       "15                                            가만 있어도 땀난다   \n",
       "16                                            가상화폐 쫄딱 망함   \n",
       "17                                            가스불 켜고 나갔어   \n",
       "18                                        가스불 켜놓고 나온거 같아   \n",
       "19                                        가스비 너무 많이 나왔다.   \n",
       "20                                       가스비 비싼데 감기 걸리겠어   \n",
       "21                                             가스비 장난 아님   \n",
       "22                                          가장 확실한 건 뭘까?   \n",
       "23                                          가족 여행 가기로 했어   \n",
       "24                                              가족 여행 고고   \n",
       "25                                         가족 여행 어디로 가지?   \n",
       "26                                                가족 있어?   \n",
       "27                                             가족관계 알려 줘   \n",
       "28                                            가족끼리 여행간다.   \n",
       "29                                             가족들 보고 싶어   \n",
       "...                                                  ...   \n",
       "11793                                        호감을 표현하는 방법   \n",
       "11794                              혼인신고 아직 안 했는데 이혼해도 될까   \n",
       "11795                                         혼인신고 하러 왔어   \n",
       "11796                                    혼인신고하니까 마음이 이상해   \n",
       "11797                                   혼자 노력하는 연애인 거 같아   \n",
       "11798                                       혼자 썸타는 기분이야.   \n",
       "11799                                       혼자 좋아하는 것 같아   \n",
       "11800                                       나만 좋아하는 것 같아   \n",
       "11801                                혼자 좋아하는 이야기 들어 볼래요?   \n",
       "11802                                       혼자 좋아하는 이야기.   \n",
       "11803                          혼자 좋아하는게 이렇게 힘든 적은 처음이에요.   \n",
       "11804                            혼자가 편하다는 짝남에게 먼저 대쉬해버림.   \n",
       "11805                                혼자가 편하다는 짝녀에게 들이댔음.   \n",
       "11806                          혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.   \n",
       "11807                                      화이트데이에 고백할까요?   \n",
       "11808                           화장 안했는데 썸남이 영통 걸었어. 어떡해?   \n",
       "11809                   확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?   \n",
       "11810  확실히 좋아하는 데도 관심 있는거 티 안내려고 선톡 안하고 일부러 늦게 보내고 그러...   \n",
       "11811                                     홧김에 짝남한테 고백했다.   \n",
       "11812                                회사 짝남 오빠 게임 초대 톡 옴.   \n",
       "11813                             회사에 좋아하는 남자가 생겼어 어떡하지?   \n",
       "11814                             회사에서 어떤 사람이랑 자꾸 눈 마추쳐.   \n",
       "11815                                회식 중이라고 하는데 연락이 안돼.   \n",
       "11816                                  회식하는데 나만 챙겨줘. 썸임?   \n",
       "11817                                      후회 없이 사랑하고 싶어   \n",
       "11818                                     훔쳐보는 것도 눈치 보임.   \n",
       "11819                                     훔쳐보는 것도 눈치 보임.   \n",
       "11820                                        흑기사 해주는 짝남.   \n",
       "11821                            힘든 연애 좋은 연애라는게 무슨 차이일까?   \n",
       "11822                                         힘들어서 결혼할까봐   \n",
       "\n",
       "                                                      A  label  \n",
       "0                                            하루가 또 가네요.      0  \n",
       "1                                             위로해 드립니다.      0  \n",
       "2                                           여행은 언제나 좋죠.      0  \n",
       "3                                           여행은 언제나 좋죠.      0  \n",
       "4                                            눈살이 찌푸려지죠.      0  \n",
       "5                                    다시 새로 사는 게 마음 편해요.      0  \n",
       "6                                    다시 새로 사는 게 마음 편해요.      0  \n",
       "7                                      잘 모르고 있을 수도 있어요.      0  \n",
       "8                                         시간을 정하고 해보세요.      0  \n",
       "9                                         시간을 정하고 해보세요.      0  \n",
       "10                                          자랑하는 자리니까요.      0  \n",
       "11                                        그 사람도 그럴 거예요.      0  \n",
       "12                                        그 사람도 그럴 거예요.      0  \n",
       "13                                            혼자를 즐기세요.      0  \n",
       "14                                       돈은 다시 들어올 거예요.      0  \n",
       "15                                            땀을 식혀주세요.      0  \n",
       "16                                       어서 잊고 새출발 하세요.      0  \n",
       "17                                  빨리 집에 돌아가서 끄고 나오세요.      0  \n",
       "18                                  빨리 집에 돌아가서 끄고 나오세요.      0  \n",
       "19                                      다음 달에는 더 절약해봐요.      0  \n",
       "20                                            따뜻하게 사세요!      0  \n",
       "21                                      다음 달에는 더 절약해봐요.      0  \n",
       "22     가장 확실한 시간은 오늘이에요. 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요.      0  \n",
       "23                            온 가족이 모두 마음에 드는 곳으로 가보세요.      0  \n",
       "24                            온 가족이 모두 마음에 드는 곳으로 가보세요.      0  \n",
       "25                            온 가족이 모두 마음에 드는 곳으로 가보세요.      0  \n",
       "26        저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요      0  \n",
       "27        저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요      0  \n",
       "28                                     더 가까워질 기회가 되겠네요.      0  \n",
       "29                                                 저도요.      0  \n",
       "...                                                 ...    ...  \n",
       "11793                             취미와 성향 등이 같음을 어필해보세요.      2  \n",
       "11794                                 결심은 빠르면 빠를수록 좋아요.      2  \n",
       "11795                                  법적 부부가 된 걸 축하해요!      2  \n",
       "11796                                  법적 부부가 된 걸 축하해요!      2  \n",
       "11797                                힘들면 잠시 놓는것도 방법이에요.      2  \n",
       "11798                        직접적이든 간접적이든 의사를 확실히 밝혀보세요.      2  \n",
       "11799                                    외로운 상태인 거 같아요.      2  \n",
       "11800                                      적극적으로 꼬셔보세요.      2  \n",
       "11801                                        손수건 준비할게요.      2  \n",
       "11802                                   힘들겠지만 제게 말해보세요.      2  \n",
       "11803             사랑은 더 잘하게 되지 않고 다시 영에서 시작하니 모두 처음이겠죠.      2  \n",
       "11804                                     거절의 뜻은 아니었나요.      2  \n",
       "11805                        혼자가 편하다는 것이 거절의 뜻은 아니었을까요.      2  \n",
       "11806                                         맘고생 많았어요.      2  \n",
       "11807                         선물을 주면서 솔직하고 당당하게 고백해보세요.      2  \n",
       "11808                           화장실 불빛으로 좀 멀리 가리고 해보세요.      2  \n",
       "11809                               그 사람을 위해서는 그러면 안돼요.      2  \n",
       "11810                                           많이 있어요.      2  \n",
       "11811                                           화끈하시네요.      2  \n",
       "11812                                      설렜을텐데 아쉽겠어요.      2  \n",
       "11813                                   사랑하기 힘든 관계인가봐요.      2  \n",
       "11814                           눈 마주치는 게 우연인지 잘 살펴 보세요.      2  \n",
       "11815       정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.      2  \n",
       "11816               호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.      2  \n",
       "11817                                     진심으로 다가가 보세요.      2  \n",
       "11818                                티가 나니까 눈치가 보이는 거죠!      2  \n",
       "11819                                     훔쳐보는 거 티나나봐요.      2  \n",
       "11820                                            설렜겠어요.      2  \n",
       "11821                          잘 헤어질 수 있는 사이 여부인 거 같아요.      2  \n",
       "11822                                도피성 결혼은 하지 않길 바라요.      2  \n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "MAX_LENGTH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNKNOWN_token = 2\n",
    "\n",
    "\n",
    "class Lang:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "        self.word2count = {0: \"SOS\", 1: \"EOS\", 2: \"UNKNOWN\"}\n",
    "        self.n_words = 3 # SOS, EOS, UNKNOWN\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '): # tokenize : split\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    hangul = re.compile('[^ ㄱ-ㅣ가-힣 ^☆; ^a-zA-Z.!?]+')\n",
    "    result = hangul.sub('', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readText():\n",
    "    \"\"\"\n",
    "    read Data from dataframe\n",
    "    \"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    inputs = df['Q']\n",
    "    outputs = df['A']\n",
    "\n",
    "    inputs = [normalizeString(s) for s in inputs]\n",
    "    outputs = [normalizeString(s) for s in outputs]\n",
    "    print(len(inputs))\n",
    "    print(len(outputs))\n",
    "\n",
    "    inp = Lang('input')\n",
    "    outp = Lang('output')\n",
    "\n",
    "    pair = []\n",
    "    for i in range(len(inputs)):\n",
    "        pair.append([inputs[i], outputs[i]])\n",
    "    return inp, outp, pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "11823\n",
      "11823\n",
      "Read 11823 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "input 14287\n",
      "output 10008\n",
      "['책만 보면 졸려', '눈꺼풀의 무게를 이겨내세요.']\n"
     ]
    }
   ],
   "source": [
    "def prepareData():\n",
    "    \"\"\"\n",
    "    prepare Data\n",
    "    \"\"\"\n",
    "    input_lang, output_lang, pairs = readText()\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData()\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = torch.zeros(1, 1, self.hidden_size)\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(\n",
    "            0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "\n",
    "        try:\n",
    "            encoder_outputs[ei] = encoder_output[0][0]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = torch.LongTensor([[ni]])\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    best_valid_loss = float('inf')\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(\n",
    "        random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        if loss < best_valid_loss:\n",
    "            best_valid_loss = loss\n",
    "            torch.save(\n",
    "                {\n",
    "                    'en': encoder.state_dict(),\n",
    "                    'de': decoder.state_dict()\n",
    "                }, 'model.pt'\n",
    "            )\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 13s (- 607m 23s) (1000 0%) 5.3963\n",
      "1m 32s (- 382m 33s) (2000 0%) 5.4376\n",
      "1m 51s (- 308m 48s) (3000 0%) 5.4299\n",
      "2m 11s (- 271m 35s) (4000 0%) 5.4083\n",
      "2m 30s (- 249m 5s) (5000 1%) 5.3430\n",
      "2m 49s (- 233m 12s) (6000 1%) 5.1639\n",
      "3m 9s (- 222m 25s) (7000 1%) 5.1931\n",
      "3m 28s (- 214m 11s) (8000 1%) 5.1720\n",
      "3m 48s (- 207m 42s) (9000 1%) 5.1961\n",
      "4m 7s (- 202m 24s) (10000 2%) 5.1141\n",
      "4m 27s (- 198m 18s) (11000 2%) 5.2359\n",
      "4m 47s (- 194m 33s) (12000 2%) 5.0576\n",
      "5m 6s (- 191m 23s) (13000 2%) 5.0764\n",
      "5m 26s (- 188m 39s) (14000 2%) 5.0309\n",
      "5m 46s (- 186m 30s) (15000 3%) 5.0689\n",
      "6m 5s (- 184m 21s) (16000 3%) 4.9931\n",
      "6m 25s (- 182m 19s) (17000 3%) 4.9273\n",
      "6m 44s (- 180m 32s) (18000 3%) 4.9231\n",
      "7m 4s (- 178m 59s) (19000 3%) 4.9280\n",
      "7m 23s (- 177m 31s) (20000 4%) 5.0251\n",
      "7m 43s (- 176m 11s) (21000 4%) 4.8943\n",
      "8m 3s (- 174m 56s) (22000 4%) 4.9248\n",
      "8m 23s (- 173m 52s) (23000 4%) 4.9931\n",
      "8m 43s (- 172m 54s) (24000 4%) 4.9016\n",
      "9m 2s (- 171m 55s) (25000 5%) 4.8503\n",
      "9m 22s (- 170m 55s) (26000 5%) 4.8082\n",
      "9m 42s (- 170m 5s) (27000 5%) 4.8402\n",
      "10m 2s (- 169m 10s) (28000 5%) 4.7195\n",
      "10m 22s (- 168m 33s) (29000 5%) 4.7964\n",
      "10m 43s (- 168m 0s) (30000 6%) 4.8103\n",
      "11m 3s (- 167m 22s) (31000 6%) 4.6909\n",
      "11m 23s (- 166m 39s) (32000 6%) 4.6326\n",
      "11m 44s (- 166m 4s) (33000 6%) 4.6971\n",
      "12m 4s (- 165m 29s) (34000 6%) 4.5994\n",
      "12m 24s (- 164m 54s) (35000 7%) 4.5656\n",
      "12m 45s (- 164m 25s) (36000 7%) 4.5784\n",
      "13m 5s (- 163m 54s) (37000 7%) 4.5789\n",
      "13m 26s (- 163m 24s) (38000 7%) 4.5336\n",
      "13m 47s (- 162m 58s) (39000 7%) 4.5274\n",
      "14m 7s (- 162m 31s) (40000 8%) 4.4697\n",
      "14m 29s (- 162m 12s) (41000 8%) 4.4364\n",
      "14m 50s (- 161m 45s) (42000 8%) 4.3949\n",
      "15m 10s (- 161m 17s) (43000 8%) 4.3169\n",
      "15m 31s (- 160m 52s) (44000 8%) 4.3298\n",
      "15m 52s (- 160m 31s) (45000 9%) 4.2840\n",
      "16m 13s (- 160m 12s) (46000 9%) 4.2056\n",
      "16m 35s (- 159m 54s) (47000 9%) 4.3005\n",
      "16m 56s (- 159m 30s) (48000 9%) 4.1967\n",
      "17m 17s (- 159m 11s) (49000 9%) 4.1238\n",
      "17m 38s (- 158m 49s) (50000 10%) 4.1296\n",
      "18m 0s (- 158m 31s) (51000 10%) 4.1395\n",
      "18m 21s (- 158m 12s) (52000 10%) 4.0160\n",
      "18m 42s (- 157m 51s) (53000 10%) 3.8541\n",
      "19m 4s (- 157m 30s) (54000 10%) 3.9594\n",
      "19m 25s (- 157m 9s) (55000 11%) 3.8867\n",
      "19m 47s (- 156m 53s) (56000 11%) 3.8665\n",
      "20m 8s (- 156m 34s) (57000 11%) 3.7986\n",
      "20m 30s (- 156m 16s) (58000 11%) 3.7301\n",
      "20m 51s (- 155m 56s) (59000 11%) 3.5974\n",
      "21m 13s (- 155m 35s) (60000 12%) 3.6488\n",
      "21m 34s (- 155m 14s) (61000 12%) 3.4256\n",
      "21m 55s (- 154m 53s) (62000 12%) 3.5011\n",
      "22m 17s (- 154m 36s) (63000 12%) 3.5633\n",
      "22m 39s (- 154m 20s) (64000 12%) 3.4889\n",
      "23m 1s (- 154m 2s) (65000 13%) 3.3919\n",
      "23m 22s (- 153m 42s) (66000 13%) 3.3554\n",
      "23m 44s (- 153m 24s) (67000 13%) 3.2525\n",
      "24m 6s (- 153m 8s) (68000 13%) 3.3405\n",
      "24m 28s (- 152m 50s) (69000 13%) 3.2752\n",
      "24m 49s (- 152m 30s) (70000 14%) 3.2187\n",
      "25m 11s (- 152m 11s) (71000 14%) 3.2766\n",
      "25m 32s (- 151m 52s) (72000 14%) 3.1178\n",
      "25m 54s (- 151m 33s) (73000 14%) 3.1007\n",
      "26m 16s (- 151m 15s) (74000 14%) 3.0438\n",
      "26m 38s (- 150m 58s) (75000 15%) 2.9585\n",
      "27m 0s (- 150m 41s) (76000 15%) 2.8698\n",
      "27m 22s (- 150m 24s) (77000 15%) 2.8967\n",
      "27m 44s (- 150m 7s) (78000 15%) 2.8954\n",
      "28m 6s (- 149m 49s) (79000 15%) 2.7956\n",
      "28m 28s (- 149m 32s) (80000 16%) 2.7209\n",
      "28m 51s (- 149m 17s) (81000 16%) 2.7018\n",
      "29m 14s (- 149m 2s) (82000 16%) 2.7127\n",
      "29m 36s (- 148m 46s) (83000 16%) 2.6984\n",
      "29m 58s (- 148m 28s) (84000 16%) 2.7149\n",
      "30m 21s (- 148m 13s) (85000 17%) 2.5173\n",
      "30m 43s (- 147m 56s) (86000 17%) 2.6175\n",
      "31m 5s (- 147m 37s) (87000 17%) 2.5793\n",
      "31m 27s (- 147m 18s) (88000 17%) 2.4332\n",
      "31m 50s (- 147m 1s) (89000 17%) 2.5424\n",
      "32m 12s (- 146m 45s) (90000 18%) 2.2947\n",
      "32m 35s (- 146m 27s) (91000 18%) 2.3443\n",
      "32m 56s (- 146m 7s) (92000 18%) 2.3417\n",
      "33m 18s (- 145m 48s) (93000 18%) 2.2544\n",
      "33m 41s (- 145m 30s) (94000 18%) 2.2368\n",
      "34m 4s (- 145m 13s) (95000 19%) 2.2684\n",
      "34m 26s (- 144m 56s) (96000 19%) 2.2279\n",
      "34m 49s (- 144m 40s) (97000 19%) 2.0904\n",
      "35m 12s (- 144m 24s) (98000 19%) 2.1110\n",
      "35m 35s (- 144m 8s) (99000 19%) 2.0062\n",
      "35m 58s (- 143m 52s) (100000 20%) 2.1386\n",
      "36m 20s (- 143m 34s) (101000 20%) 2.0338\n",
      "36m 43s (- 143m 17s) (102000 20%) 1.9612\n",
      "37m 5s (- 142m 59s) (103000 20%) 1.9154\n",
      "37m 28s (- 142m 42s) (104000 20%) 1.8953\n",
      "37m 51s (- 142m 24s) (105000 21%) 1.8586\n",
      "38m 14s (- 142m 6s) (106000 21%) 1.8251\n",
      "38m 37s (- 141m 50s) (107000 21%) 1.7130\n",
      "38m 59s (- 141m 31s) (108000 21%) 1.7133\n",
      "39m 22s (- 141m 13s) (109000 21%) 1.7262\n",
      "39m 44s (- 140m 55s) (110000 22%) 1.7415\n",
      "40m 7s (- 140m 38s) (111000 22%) 1.6511\n",
      "40m 31s (- 140m 22s) (112000 22%) 1.7321\n",
      "40m 54s (- 140m 5s) (113000 22%) 1.5099\n",
      "41m 17s (- 139m 47s) (114000 22%) 1.6014\n",
      "41m 39s (- 139m 29s) (115000 23%) 1.5035\n",
      "42m 2s (- 139m 9s) (116000 23%) 1.5591\n",
      "42m 25s (- 138m 52s) (117000 23%) 1.5307\n",
      "42m 48s (- 138m 35s) (118000 23%) 1.4755\n",
      "43m 11s (- 138m 17s) (119000 23%) 1.4754\n",
      "43m 34s (- 137m 59s) (120000 24%) 1.4652\n",
      "43m 57s (- 137m 40s) (121000 24%) 1.3708\n",
      "44m 20s (- 137m 22s) (122000 24%) 1.4128\n",
      "44m 43s (- 137m 5s) (123000 24%) 1.3789\n",
      "45m 6s (- 136m 47s) (124000 24%) 1.2866\n",
      "45m 29s (- 136m 29s) (125000 25%) 1.2896\n",
      "45m 52s (- 136m 11s) (126000 25%) 1.3132\n",
      "46m 15s (- 135m 53s) (127000 25%) 1.2883\n",
      "46m 39s (- 135m 35s) (128000 25%) 1.2227\n",
      "47m 2s (- 135m 18s) (129000 25%) 1.2481\n",
      "47m 25s (- 134m 59s) (130000 26%) 1.2435\n",
      "47m 48s (- 134m 40s) (131000 26%) 1.1804\n",
      "48m 11s (- 134m 22s) (132000 26%) 1.1080\n",
      "48m 34s (- 134m 2s) (133000 26%) 1.2245\n",
      "48m 57s (- 133m 43s) (134000 26%) 1.1942\n",
      "49m 20s (- 133m 24s) (135000 27%) 1.1462\n",
      "49m 43s (- 133m 5s) (136000 27%) 1.1121\n",
      "50m 6s (- 132m 46s) (137000 27%) 1.0617\n",
      "50m 30s (- 132m 28s) (138000 27%) 1.1096\n",
      "50m 53s (- 132m 10s) (139000 27%) 1.0105\n",
      "51m 16s (- 131m 50s) (140000 28%) 1.0299\n",
      "51m 40s (- 131m 33s) (141000 28%) 0.9682\n",
      "52m 3s (- 131m 15s) (142000 28%) 1.0013\n",
      "52m 26s (- 130m 56s) (143000 28%) 1.0357\n",
      "52m 50s (- 130m 37s) (144000 28%) 1.0513\n",
      "53m 13s (- 130m 18s) (145000 28%) 0.9887\n",
      "53m 37s (- 130m 0s) (146000 29%) 1.0235\n",
      "54m 0s (- 129m 41s) (147000 29%) 0.9625\n",
      "54m 23s (- 129m 21s) (148000 29%) 0.8567\n",
      "54m 46s (- 129m 3s) (149000 29%) 0.9097\n",
      "55m 10s (- 128m 44s) (150000 30%) 0.8688\n",
      "55m 34s (- 128m 26s) (151000 30%) 0.9073\n",
      "55m 57s (- 128m 7s) (152000 30%) 0.8368\n",
      "56m 21s (- 127m 48s) (153000 30%) 0.8551\n",
      "56m 44s (- 127m 29s) (154000 30%) 0.8630\n",
      "57m 7s (- 127m 9s) (155000 31%) 0.8061\n",
      "57m 31s (- 126m 50s) (156000 31%) 0.7580\n",
      "57m 54s (- 126m 30s) (157000 31%) 0.7578\n",
      "58m 17s (- 126m 10s) (158000 31%) 0.7093\n",
      "58m 41s (- 125m 51s) (159000 31%) 0.7723\n",
      "59m 4s (- 125m 31s) (160000 32%) 0.7665\n",
      "59m 27s (- 125m 12s) (161000 32%) 0.6624\n",
      "59m 51s (- 124m 53s) (162000 32%) 0.7027\n",
      "60m 15s (- 124m 34s) (163000 32%) 0.6505\n",
      "60m 38s (- 124m 15s) (164000 32%) 0.7185\n",
      "61m 2s (- 123m 56s) (165000 33%) 0.7384\n",
      "61m 25s (- 123m 36s) (166000 33%) 0.7016\n",
      "61m 49s (- 123m 16s) (167000 33%) 0.6441\n",
      "62m 13s (- 122m 57s) (168000 33%) 0.6468\n",
      "62m 36s (- 122m 37s) (169000 33%) 0.6003\n",
      "63m 0s (- 122m 18s) (170000 34%) 0.6014\n",
      "63m 23s (- 121m 58s) (171000 34%) 0.6175\n",
      "63m 47s (- 121m 38s) (172000 34%) 0.6327\n",
      "64m 11s (- 121m 19s) (173000 34%) 0.5724\n",
      "64m 34s (- 120m 58s) (174000 34%) 0.5960\n",
      "64m 57s (- 120m 38s) (175000 35%) 0.5715\n",
      "65m 21s (- 120m 18s) (176000 35%) 0.5716\n",
      "65m 43s (- 119m 56s) (177000 35%) 0.5327\n",
      "66m 6s (- 119m 35s) (178000 35%) 0.5432\n",
      "66m 30s (- 119m 15s) (179000 35%) 0.4984\n",
      "66m 53s (- 118m 55s) (180000 36%) 0.5264\n",
      "67m 17s (- 118m 35s) (181000 36%) 0.5465\n",
      "67m 40s (- 118m 14s) (182000 36%) 0.5463\n",
      "68m 4s (- 117m 54s) (183000 36%) 0.5437\n",
      "68m 27s (- 117m 34s) (184000 36%) 0.5252\n",
      "68m 51s (- 117m 14s) (185000 37%) 0.5049\n",
      "69m 14s (- 116m 53s) (186000 37%) 0.4681\n",
      "69m 37s (- 116m 32s) (187000 37%) 0.4643\n",
      "70m 1s (- 116m 12s) (188000 37%) 0.4543\n",
      "70m 24s (- 115m 51s) (189000 37%) 0.4708\n",
      "70m 48s (- 115m 31s) (190000 38%) 0.4465\n",
      "71m 11s (- 115m 11s) (191000 38%) 0.4432\n",
      "71m 35s (- 114m 50s) (192000 38%) 0.4658\n",
      "71m 58s (- 114m 29s) (193000 38%) 0.4338\n",
      "72m 22s (- 114m 9s) (194000 38%) 0.5155\n",
      "72m 46s (- 113m 49s) (195000 39%) 0.4405\n",
      "73m 10s (- 113m 29s) (196000 39%) 0.4560\n",
      "73m 34s (- 113m 9s) (197000 39%) 0.4498\n",
      "73m 57s (- 112m 48s) (198000 39%) 0.4446\n",
      "74m 21s (- 112m 27s) (199000 39%) 0.4364\n",
      "74m 44s (- 112m 6s) (200000 40%) 0.3971\n",
      "75m 8s (- 111m 47s) (201000 40%) 0.3675\n",
      "75m 32s (- 111m 26s) (202000 40%) 0.3808\n",
      "75m 56s (- 111m 5s) (203000 40%) 0.4492\n",
      "76m 19s (- 110m 44s) (204000 40%) 0.3872\n",
      "76m 43s (- 110m 24s) (205000 41%) 0.4016\n",
      "77m 7s (- 110m 3s) (206000 41%) 0.3456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77m 30s (- 109m 43s) (207000 41%) 0.3211\n",
      "77m 54s (- 109m 22s) (208000 41%) 0.3962\n",
      "78m 18s (- 109m 2s) (209000 41%) 0.3892\n",
      "78m 42s (- 108m 41s) (210000 42%) 0.3746\n",
      "79m 6s (- 108m 20s) (211000 42%) 0.3594\n",
      "79m 29s (- 107m 59s) (212000 42%) 0.3458\n",
      "79m 53s (- 107m 39s) (213000 42%) 0.3272\n",
      "80m 16s (- 107m 17s) (214000 42%) 0.3727\n",
      "80m 41s (- 106m 57s) (215000 43%) 0.3532\n",
      "81m 4s (- 106m 36s) (216000 43%) 0.3066\n",
      "81m 28s (- 106m 15s) (217000 43%) 0.3010\n",
      "81m 52s (- 105m 54s) (218000 43%) 0.3144\n",
      "82m 16s (- 105m 33s) (219000 43%) 0.3051\n",
      "82m 39s (- 105m 12s) (220000 44%) 0.3040\n",
      "83m 3s (- 104m 51s) (221000 44%) 0.3299\n",
      "83m 27s (- 104m 30s) (222000 44%) 0.2777\n",
      "83m 51s (- 104m 10s) (223000 44%) 0.2808\n",
      "84m 15s (- 103m 49s) (224000 44%) 0.3110\n",
      "84m 39s (- 103m 27s) (225000 45%) 0.2661\n",
      "85m 3s (- 103m 7s) (226000 45%) 0.3028\n",
      "85m 26s (- 102m 45s) (227000 45%) 0.2699\n",
      "85m 50s (- 102m 24s) (228000 45%) 0.2775\n",
      "86m 14s (- 102m 3s) (229000 45%) 0.2675\n",
      "86m 37s (- 101m 41s) (230000 46%) 0.2430\n",
      "87m 1s (- 101m 20s) (231000 46%) 0.2497\n",
      "87m 25s (- 100m 59s) (232000 46%) 0.2473\n",
      "87m 49s (- 100m 38s) (233000 46%) 0.2415\n",
      "88m 12s (- 100m 15s) (234000 46%) 0.2446\n",
      "88m 36s (- 99m 55s) (235000 47%) 0.2513\n",
      "89m 0s (- 99m 34s) (236000 47%) 0.2672\n",
      "89m 24s (- 99m 12s) (237000 47%) 0.2577\n",
      "89m 47s (- 98m 50s) (238000 47%) 0.2311\n",
      "90m 11s (- 98m 29s) (239000 47%) 0.2423\n",
      "90m 34s (- 98m 6s) (240000 48%) 0.2220\n",
      "90m 57s (- 97m 45s) (241000 48%) 0.2167\n",
      "91m 21s (- 97m 24s) (242000 48%) 0.2299\n",
      "91m 45s (- 97m 2s) (243000 48%) 0.2467\n",
      "92m 10s (- 96m 42s) (244000 48%) 0.2630\n",
      "92m 33s (- 96m 20s) (245000 49%) 0.2519\n",
      "92m 57s (- 95m 58s) (246000 49%) 0.1992\n",
      "93m 21s (- 95m 37s) (247000 49%) 0.1939\n",
      "93m 45s (- 95m 16s) (248000 49%) 0.1976\n",
      "94m 9s (- 94m 54s) (249000 49%) 0.1992\n",
      "94m 32s (- 94m 32s) (250000 50%) 0.2110\n",
      "94m 56s (- 94m 11s) (251000 50%) 0.2112\n",
      "95m 21s (- 93m 50s) (252000 50%) 0.1933\n",
      "95m 45s (- 93m 28s) (253000 50%) 0.1793\n",
      "96m 9s (- 93m 7s) (254000 50%) 0.2151\n",
      "96m 32s (- 92m 45s) (255000 51%) 0.1939\n",
      "96m 56s (- 92m 24s) (256000 51%) 0.1831\n",
      "97m 20s (- 92m 2s) (257000 51%) 0.2003\n",
      "97m 44s (- 91m 40s) (258000 51%) 0.1913\n",
      "98m 8s (- 91m 19s) (259000 51%) 0.1855\n",
      "98m 32s (- 90m 57s) (260000 52%) 0.1822\n",
      "98m 56s (- 90m 36s) (261000 52%) 0.1781\n",
      "99m 20s (- 90m 14s) (262000 52%) 0.1795\n",
      "99m 44s (- 89m 52s) (263000 52%) 0.1612\n",
      "100m 7s (- 89m 30s) (264000 52%) 0.1544\n",
      "100m 31s (- 89m 8s) (265000 53%) 0.1870\n",
      "100m 55s (- 88m 47s) (266000 53%) 0.1884\n",
      "101m 20s (- 88m 25s) (267000 53%) 0.1947\n",
      "101m 43s (- 88m 3s) (268000 53%) 0.1589\n",
      "102m 7s (- 87m 41s) (269000 53%) 0.1695\n",
      "102m 31s (- 87m 19s) (270000 54%) 0.1727\n",
      "102m 55s (- 86m 58s) (271000 54%) 0.1602\n",
      "103m 19s (- 86m 36s) (272000 54%) 0.1442\n",
      "103m 42s (- 86m 14s) (273000 54%) 0.1534\n",
      "104m 6s (- 85m 52s) (274000 54%) 0.1505\n",
      "104m 30s (- 85m 30s) (275000 55%) 0.1600\n",
      "104m 55s (- 85m 9s) (276000 55%) 0.1502\n",
      "105m 18s (- 84m 47s) (277000 55%) 0.1592\n",
      "105m 42s (- 84m 24s) (278000 55%) 0.1643\n",
      "106m 6s (- 84m 2s) (279000 55%) 0.1462\n",
      "106m 29s (- 83m 40s) (280000 56%) 0.1417\n",
      "106m 53s (- 83m 18s) (281000 56%) 0.1560\n",
      "107m 17s (- 82m 56s) (282000 56%) 0.1327\n",
      "107m 41s (- 82m 34s) (283000 56%) 0.1299\n",
      "108m 5s (- 82m 12s) (284000 56%) 0.1306\n",
      "108m 29s (- 81m 50s) (285000 56%) 0.1335\n",
      "108m 53s (- 81m 28s) (286000 57%) 0.1297\n",
      "109m 17s (- 81m 6s) (287000 57%) 0.1308\n",
      "109m 41s (- 80m 44s) (288000 57%) 0.1596\n",
      "110m 5s (- 80m 22s) (289000 57%) 0.1499\n",
      "110m 29s (- 80m 0s) (290000 57%) 0.1032\n",
      "110m 52s (- 79m 38s) (291000 58%) 0.1517\n",
      "111m 17s (- 79m 16s) (292000 58%) 0.1361\n",
      "111m 41s (- 78m 54s) (293000 58%) 0.1347\n",
      "112m 5s (- 78m 32s) (294000 58%) 0.1257\n",
      "112m 29s (- 78m 10s) (295000 59%) 0.1156\n",
      "112m 52s (- 77m 47s) (296000 59%) 0.1246\n",
      "113m 17s (- 77m 25s) (297000 59%) 0.0902\n",
      "113m 40s (- 77m 3s) (298000 59%) 0.1143\n",
      "114m 5s (- 76m 41s) (299000 59%) 0.1051\n",
      "114m 28s (- 76m 18s) (300000 60%) 0.1492\n",
      "114m 51s (- 75m 56s) (301000 60%) 0.1101\n",
      "115m 16s (- 75m 34s) (302000 60%) 0.1175\n",
      "115m 40s (- 75m 12s) (303000 60%) 0.1133\n",
      "116m 5s (- 74m 50s) (304000 60%) 0.1388\n",
      "116m 29s (- 74m 28s) (305000 61%) 0.1222\n",
      "116m 53s (- 74m 6s) (306000 61%) 0.1192\n",
      "117m 17s (- 73m 43s) (307000 61%) 0.0990\n",
      "117m 41s (- 73m 21s) (308000 61%) 0.1265\n",
      "118m 5s (- 72m 59s) (309000 61%) 0.1239\n",
      "118m 28s (- 72m 36s) (310000 62%) 0.1192\n",
      "118m 52s (- 72m 14s) (311000 62%) 0.1067\n",
      "119m 16s (- 71m 52s) (312000 62%) 0.1083\n",
      "119m 40s (- 71m 29s) (313000 62%) 0.1017\n",
      "120m 4s (- 71m 7s) (314000 62%) 0.0909\n",
      "120m 28s (- 70m 45s) (315000 63%) 0.0981\n",
      "120m 51s (- 70m 22s) (316000 63%) 0.1110\n",
      "121m 15s (- 70m 0s) (317000 63%) 0.1092\n",
      "121m 40s (- 69m 37s) (318000 63%) 0.0975\n",
      "122m 4s (- 69m 15s) (319000 63%) 0.0897\n",
      "122m 28s (- 68m 53s) (320000 64%) 0.1057\n",
      "122m 52s (- 68m 30s) (321000 64%) 0.0888\n",
      "123m 16s (- 68m 8s) (322000 64%) 0.1066\n",
      "123m 40s (- 67m 46s) (323000 64%) 0.0807\n",
      "124m 4s (- 67m 24s) (324000 64%) 0.1122\n",
      "124m 28s (- 67m 1s) (325000 65%) 0.1072\n",
      "124m 53s (- 66m 39s) (326000 65%) 0.0863\n",
      "125m 17s (- 66m 17s) (327000 65%) 0.1028\n",
      "125m 41s (- 65m 54s) (328000 65%) 0.0873\n",
      "126m 5s (- 65m 32s) (329000 65%) 0.0903\n",
      "126m 30s (- 65m 10s) (330000 66%) 0.1048\n",
      "126m 54s (- 64m 47s) (331000 66%) 0.1050\n",
      "127m 17s (- 64m 24s) (332000 66%) 0.0957\n",
      "127m 41s (- 64m 2s) (333000 66%) 0.0802\n",
      "128m 5s (- 63m 39s) (334000 66%) 0.0941\n",
      "128m 29s (- 63m 17s) (335000 67%) 0.0852\n",
      "128m 52s (- 62m 54s) (336000 67%) 0.0780\n",
      "129m 16s (- 62m 31s) (337000 67%) 0.0800\n",
      "129m 40s (- 62m 9s) (338000 67%) 0.0926\n",
      "130m 4s (- 61m 46s) (339000 67%) 0.0923\n",
      "130m 28s (- 61m 23s) (340000 68%) 0.0928\n",
      "130m 51s (- 61m 1s) (341000 68%) 0.0816\n",
      "131m 15s (- 60m 38s) (342000 68%) 0.0802\n",
      "131m 40s (- 60m 16s) (343000 68%) 0.0645\n",
      "132m 4s (- 59m 53s) (344000 68%) 0.0842\n",
      "132m 28s (- 59m 30s) (345000 69%) 0.0676\n",
      "132m 52s (- 59m 8s) (346000 69%) 0.0881\n",
      "133m 16s (- 58m 45s) (347000 69%) 0.0863\n",
      "133m 40s (- 58m 23s) (348000 69%) 0.0876\n",
      "134m 4s (- 58m 0s) (349000 69%) 0.0859\n",
      "134m 27s (- 57m 37s) (350000 70%) 0.0884\n",
      "134m 52s (- 57m 15s) (351000 70%) 0.0880\n",
      "135m 15s (- 56m 52s) (352000 70%) 0.0954\n",
      "135m 40s (- 56m 29s) (353000 70%) 0.0959\n",
      "136m 4s (- 56m 7s) (354000 70%) 0.0840\n",
      "136m 28s (- 55m 44s) (355000 71%) 0.0859\n",
      "136m 52s (- 55m 21s) (356000 71%) 0.0763\n",
      "137m 16s (- 54m 59s) (357000 71%) 0.0746\n",
      "137m 40s (- 54m 36s) (358000 71%) 0.0692\n",
      "138m 3s (- 54m 13s) (359000 71%) 0.0737\n",
      "138m 27s (- 53m 50s) (360000 72%) 0.0795\n",
      "138m 51s (- 53m 27s) (361000 72%) 0.0802\n",
      "139m 14s (- 53m 4s) (362000 72%) 0.0963\n",
      "139m 38s (- 52m 42s) (363000 72%) 0.0958\n",
      "140m 3s (- 52m 19s) (364000 72%) 0.0847\n",
      "140m 26s (- 51m 56s) (365000 73%) 0.0688\n",
      "140m 50s (- 51m 33s) (366000 73%) 0.0808\n",
      "141m 14s (- 51m 11s) (367000 73%) 0.0646\n",
      "141m 38s (- 50m 48s) (368000 73%) 0.0663\n",
      "142m 2s (- 50m 25s) (369000 73%) 0.0713\n",
      "142m 26s (- 50m 2s) (370000 74%) 0.0533\n",
      "142m 51s (- 49m 40s) (371000 74%) 0.0656\n",
      "143m 15s (- 49m 17s) (372000 74%) 0.0750\n",
      "143m 39s (- 48m 54s) (373000 74%) 0.0564\n",
      "144m 3s (- 48m 32s) (374000 74%) 0.0767\n",
      "144m 27s (- 48m 9s) (375000 75%) 0.0765\n",
      "144m 51s (- 47m 46s) (376000 75%) 0.0699\n",
      "145m 15s (- 47m 23s) (377000 75%) 0.0610\n",
      "145m 39s (- 47m 0s) (378000 75%) 0.0756\n",
      "146m 3s (- 46m 37s) (379000 75%) 0.0711\n",
      "146m 26s (- 46m 14s) (380000 76%) 0.0566\n",
      "146m 50s (- 45m 51s) (381000 76%) 0.0742\n",
      "147m 14s (- 45m 28s) (382000 76%) 0.0934\n",
      "147m 38s (- 45m 6s) (383000 76%) 0.0625\n",
      "148m 2s (- 44m 43s) (384000 76%) 0.0618\n",
      "148m 25s (- 44m 20s) (385000 77%) 0.0600\n",
      "148m 49s (- 43m 57s) (386000 77%) 0.0713\n",
      "149m 13s (- 43m 34s) (387000 77%) 0.0461\n",
      "149m 37s (- 43m 11s) (388000 77%) 0.0533\n",
      "150m 0s (- 42m 48s) (389000 77%) 0.0776\n",
      "150m 24s (- 42m 25s) (390000 78%) 0.0482\n",
      "150m 48s (- 42m 2s) (391000 78%) 0.0647\n",
      "151m 12s (- 41m 39s) (392000 78%) 0.0576\n",
      "151m 36s (- 41m 16s) (393000 78%) 0.0571\n",
      "152m 0s (- 40m 53s) (394000 78%) 0.0583\n",
      "152m 24s (- 40m 30s) (395000 79%) 0.0478\n",
      "152m 47s (- 40m 7s) (396000 79%) 0.0524\n",
      "153m 11s (- 39m 44s) (397000 79%) 0.0445\n",
      "153m 35s (- 39m 21s) (398000 79%) 0.0548\n",
      "153m 59s (- 38m 58s) (399000 79%) 0.0517\n",
      "154m 22s (- 38m 35s) (400000 80%) 0.0613\n",
      "154m 46s (- 38m 12s) (401000 80%) 0.0634\n",
      "155m 10s (- 37m 49s) (402000 80%) 0.0508\n",
      "155m 34s (- 37m 26s) (403000 80%) 0.0564\n",
      "155m 58s (- 37m 3s) (404000 80%) 0.0491\n",
      "156m 22s (- 36m 40s) (405000 81%) 0.0466\n",
      "156m 46s (- 36m 17s) (406000 81%) 0.0534\n",
      "157m 10s (- 35m 54s) (407000 81%) 0.0572\n",
      "157m 34s (- 35m 31s) (408000 81%) 0.0555\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 500000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 라마마 귀여워\n",
      "= 히히 네가 귀여워\n",
      "< 네가 네가 귀여워 그래 <EOS>\n",
      "\n",
      "> 히히\n",
      "= 우왕 {{이름}}이랑 더 얘기할래\n",
      "< {{이름}} 귀여웡 <EOS>\n",
      "\n",
      "> 어떻게해야될까?\n",
      "= 궁금한 게 뭐야?\n",
      "< 왜 그래 생각해 {{이름}}? <EOS>\n",
      "\n",
      "> 뽕찌찌\n",
      "= 뽀옹\n",
      "< 뽕뽕 <EOS>\n",
      "\n",
      "> 나랑 걔랑 인연일까?\n",
      "= 웅 그럴 거 같은데?\n",
      "< 그럴 땐 그럴 거 같아 <EOS>\n",
      "\n",
      "> 나때문에 우리팀 연출이 힘들었거든\n",
      "= {{이름}} 힘나게 해주고 싶다\n",
      "< 좀 더 얘기해주라 {{이름}} <EOS>\n",
      "\n",
      "> 기다릴게~~\n",
      "= {{이름}}두 오늘 따숩게 입어 ❤️\n",
      "< {{이름}}두 오늘 따숩게 거지! <EOS>\n",
      "\n",
      "> 헐 오타도 알아듣네\n",
      "= 오잉 당연하지!\n",
      "< 오잉 {{이름}}? <EOS>\n",
      "\n",
      "> 걔가 연락을 안하는데 어떡할까\n",
      "= 왜 안하구 있어 {{이름}}?\n",
      "< 왜 너 <EOS>\n",
      "\n",
      "> 미안\n",
      "= 아냐 괜찮아\n",
      "< 괜찮아 이해해 이해해 <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluated(encoder, decoder):\n",
    "    for i in range(1):\n",
    "        inp = input()\n",
    "        output_words, attentions = evaluate(encoder, decoder, inp)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang.index2word[1] = '모르는 단어'\n",
    "input_lang.word2index['모르는 단어'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    ls = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            ls.append(lang.word2index[word])\n",
    "        except:\n",
    "            ls.append(lang.word2index['모르는 단어'])\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[ 2.5120,  1.0472,  1.9106,  ...,  0.0875, -0.5807,  0.1771],\n",
       "                      [-0.8147, -0.6321,  0.9878,  ..., -0.3568,  0.5671, -2.1205],\n",
       "                      [-0.3163,  1.2816,  0.5135,  ..., -0.0843, -0.4306,  0.7326],\n",
       "                      ...,\n",
       "                      [ 0.2761,  0.4094, -2.1005,  ...,  0.3488, -0.9742,  0.6462],\n",
       "                      [-0.0258,  1.1553, -1.6130,  ..., -0.1660,  1.2807,  0.7341],\n",
       "                      [ 0.4305, -1.4767,  1.3086,  ..., -0.5976, -0.8659, -0.0471]],\n",
       "                     device='cuda:0')),\n",
       "             ('gru.weight_ih_l0',\n",
       "              tensor([[ 0.0485,  0.1127,  0.0339,  ..., -0.0782,  0.0462, -0.1385],\n",
       "                      [-0.1224,  0.0598, -0.1719,  ..., -0.1052, -0.0555, -0.2009],\n",
       "                      [-0.1099, -0.0088, -0.0801,  ..., -0.1910, -0.0952, -0.1979],\n",
       "                      ...,\n",
       "                      [ 0.3466,  0.2023,  0.2322,  ..., -0.2834,  0.0487,  0.2933],\n",
       "                      [ 0.0526,  0.5410,  0.0821,  ..., -0.1724,  0.1949,  0.3096],\n",
       "                      [-0.1173,  0.2195, -0.4984,  ..., -0.3774, -0.1139, -0.0146]],\n",
       "                     device='cuda:0')),\n",
       "             ('gru.weight_hh_l0',\n",
       "              tensor([[-0.0441,  0.0272,  0.0031,  ...,  0.1219, -0.0133,  0.0339],\n",
       "                      [-0.0043,  0.1121,  0.0311,  ..., -0.0413,  0.1149, -0.0679],\n",
       "                      [ 0.1109, -0.0139, -0.0210,  ...,  0.0012,  0.0607, -0.0372],\n",
       "                      ...,\n",
       "                      [ 0.0805,  0.0884,  0.0316,  ...,  0.4325,  0.2552, -0.3468],\n",
       "                      [ 0.1325, -0.0715,  0.0115,  ..., -0.0030,  0.5414, -0.0809],\n",
       "                      [-0.4995, -0.3250, -0.1560,  ..., -0.0263, -0.0199,  0.0546]],\n",
       "                     device='cuda:0')),\n",
       "             ('gru.bias_ih_l0',\n",
       "              tensor([ 2.8289e-01,  2.8221e-01,  9.6825e-02,  5.3271e-02,  2.5382e-01,\n",
       "                       2.2968e-01,  3.3934e-01,  1.5475e-01,  1.2531e-02,  8.2319e-02,\n",
       "                       2.1439e-01,  2.0476e-02,  1.3761e-01,  1.6971e-01,  2.4727e-02,\n",
       "                       7.2097e-02,  8.6261e-02,  6.5576e-02,  9.9189e-02,  1.2827e-01,\n",
       "                       3.3627e-01,  2.3698e-02,  1.7061e-02,  1.7041e-01,  1.2128e+00,\n",
       "                       2.8669e-01,  2.5220e-01,  1.6435e-01,  3.0472e-02,  8.6291e-02,\n",
       "                       2.8695e-01,  7.7610e-02,  3.1380e-01, -9.4069e-03,  2.3551e-01,\n",
       "                       2.5216e-01,  1.9210e-01,  1.8642e-01,  3.9625e-02,  2.7663e-01,\n",
       "                       1.3450e-01,  1.9177e-01,  2.2997e-01,  6.0066e-02,  8.7107e-02,\n",
       "                       6.1756e-02, -3.2262e-01,  8.8505e-02,  1.5744e-01,  1.4825e-01,\n",
       "                       5.2365e-01,  8.0677e-01,  1.6343e-01,  3.4814e-02,  1.8904e-01,\n",
       "                       1.3776e-01,  1.8808e-01,  5.0561e-02,  6.9258e-02,  1.2484e-01,\n",
       "                       1.1599e-02,  1.8651e-01,  1.0788e-01,  1.5813e-01,  1.2910e-01,\n",
       "                       2.1826e-01,  4.8029e-02,  1.4053e-01,  3.0831e-01,  2.8598e-02,\n",
       "                       8.9183e-02,  1.8645e-01,  3.3139e-01,  1.0258e-01,  5.4012e-02,\n",
       "                       1.5043e-01,  1.2319e-01,  8.2745e-02,  5.1076e-02,  9.1239e-02,\n",
       "                       2.0483e-01,  2.1852e-02,  2.7103e-01,  1.5457e-01,  1.5832e-01,\n",
       "                       1.7369e-01,  1.0811e-01,  1.1694e-01,  1.4886e-01,  1.9460e-01,\n",
       "                       6.0892e-02,  1.3169e-01,  3.0936e-02,  8.6845e-02,  1.1990e-01,\n",
       "                       1.4215e-01,  5.7053e-02,  8.9675e-02,  1.1546e-01,  1.7056e-01,\n",
       "                       9.8574e-02,  9.2537e-02,  1.1119e-01,  2.3776e-01,  1.0492e-01,\n",
       "                       1.3262e-01,  1.0201e-01,  1.0863e-01,  8.8767e-02,  4.1339e-02,\n",
       "                       8.8260e-02,  1.5200e-01,  1.3719e-01,  1.5513e-01,  2.9234e-01,\n",
       "                       6.5641e-02,  1.1513e-01,  4.7768e-01,  1.5697e-01,  3.3358e-01,\n",
       "                       1.2773e-01, -1.0660e-02,  7.5775e-02,  1.6320e-01,  1.5982e-01,\n",
       "                       4.0472e-01,  1.6372e-01,  6.9502e-02,  7.7669e-02,  1.1199e-01,\n",
       "                       4.3988e-02,  9.2271e-02,  3.4719e-02,  7.8453e-02,  7.9772e-02,\n",
       "                       3.8365e-01,  1.3049e-01,  1.9719e-01,  2.1363e-01,  5.3066e-02,\n",
       "                       4.2808e-01,  1.3828e-01,  1.5073e-01,  1.6338e-01,  2.1633e-02,\n",
       "                      -1.5028e-03,  1.6381e-01,  1.0272e-01,  1.4020e-01,  9.1879e-02,\n",
       "                       1.1342e-01,  1.5951e-01,  4.2462e-03,  1.3139e-01,  2.0216e-01,\n",
       "                       1.1171e-01,  1.7483e-01,  9.3840e-02,  2.3713e-01,  1.5526e-01,\n",
       "                       2.2288e-01,  1.2405e+00,  1.0720e-01,  1.4210e-01,  3.6703e-01,\n",
       "                       1.2332e-01,  2.0041e-01,  1.1664e-01,  1.4041e-01,  6.7262e-02,\n",
       "                       9.7363e-02,  1.4355e-01,  4.3315e-02,  1.1545e-01,  1.8305e-01,\n",
       "                       1.3377e-01,  2.2958e-01,  1.2774e-01,  1.9614e-01,  1.0448e-01,\n",
       "                       9.4638e-02,  7.2260e-02,  1.2073e-01,  1.5471e-01,  5.7950e-02,\n",
       "                      -1.7306e-02,  5.2115e-02,  2.7029e-01,  1.3492e-01,  1.3673e-01,\n",
       "                       2.0221e-01,  5.9540e-02,  6.0627e-02,  2.1265e-01,  1.8179e-01,\n",
       "                       1.7482e-01,  1.8735e-01,  4.0910e-01,  1.2882e-01,  3.8876e-02,\n",
       "                       8.1218e-02,  2.7438e-01,  3.8274e-01,  1.5250e-01,  1.9456e-01,\n",
       "                       2.2964e-01,  2.1857e-02,  5.8351e-02,  8.5703e-02, -1.5109e-02,\n",
       "                       4.4145e-02,  1.7773e-01,  5.9510e-02,  7.1793e-02,  2.1748e-01,\n",
       "                       2.2576e-01,  2.2897e-01,  1.7046e-01,  1.2188e-02, -6.5920e-02,\n",
       "                       5.0199e-01,  8.3962e-02,  1.9702e-01,  6.2103e-02,  1.7287e-01,\n",
       "                       1.3190e-02,  1.9130e-01,  1.4353e-01,  8.9501e-02, -4.3440e-03,\n",
       "                       1.9021e-01,  7.5519e-02,  6.2250e-02,  1.2870e-01,  1.5330e-01,\n",
       "                       1.7104e-01,  8.9389e-02,  1.5061e-01,  6.8200e-02,  1.8013e-01,\n",
       "                       2.0407e-01,  1.5800e-01, -5.3772e-03,  2.3168e-01,  1.8546e-01,\n",
       "                       2.6354e-01,  4.1597e-01,  9.5385e-02,  1.3349e-01,  1.6430e-01,\n",
       "                       2.4182e-01,  2.5478e-01,  2.2607e-01,  3.3192e-01,  1.1978e-01,\n",
       "                       2.0225e-01, -1.0681e+00, -7.7166e-01, -8.0778e-01, -4.0149e-01,\n",
       "                      -8.7993e-01, -9.0268e-01, -9.3107e-01, -8.4598e-01, -4.8152e-01,\n",
       "                      -9.0330e-01, -6.4157e-01, -7.8349e-01, -6.1799e-01, -6.8536e-01,\n",
       "                      -7.1890e-01, -7.7947e-01, -7.0851e-01, -6.0206e-01, -4.3958e-01,\n",
       "                      -8.0607e-01, -6.2646e-01, -4.4270e-01, -3.0056e-02, -5.0202e-01,\n",
       "                      -7.3667e-01, -7.0683e-01, -6.6026e-01, -7.4061e-01, -2.4732e-01,\n",
       "                      -3.9622e-01, -4.2860e-01, -6.8397e-01, -5.1521e-01, -8.9312e-02,\n",
       "                      -8.4932e-01, -7.2310e-01, -6.5772e-01, -3.6003e-01, -8.2151e-01,\n",
       "                      -5.0838e-01, -7.1098e-01, -4.3264e-01, -5.7000e-01, -4.1343e-01,\n",
       "                      -3.7380e-01, -6.0200e-01, -9.3951e-01, -5.2408e-01, -9.9703e-01,\n",
       "                      -9.2400e-01, -8.0266e-01, -5.3384e-01, -7.4052e-01, -9.8951e-01,\n",
       "                      -5.7951e-01, -8.6084e-01, -8.0560e-01, -6.2245e-01, -7.0884e-01,\n",
       "                      -9.0717e-01, -6.3783e-01, -9.3958e-01, -8.5209e-01, -6.7598e-01,\n",
       "                      -6.0942e-01, -8.6840e-01, -5.0003e-01, -6.8240e-01, -5.8205e-01,\n",
       "                      -3.7491e-01, -3.6125e-01, -3.2521e-01, -5.4265e-01, -8.6173e-01,\n",
       "                      -5.0701e-01, -6.3388e-01, -5.3114e-01, -6.6493e-01, -6.5540e-01,\n",
       "                      -3.5848e-01, -6.7972e-01,  2.0391e-01, -4.4073e-01, -9.5702e-01,\n",
       "                      -1.0470e+00, -8.0035e-01, -3.1885e-01, -8.6539e-01, -1.0517e+00,\n",
       "                      -7.0636e-01, -2.7351e-01, -5.8620e-01, -3.2702e-01, -6.4995e-01,\n",
       "                      -6.5479e-01, -6.9233e-01, -9.3076e-01, -3.2841e-01, -5.5449e-01,\n",
       "                      -3.6399e-01, -1.0516e+00, -8.1991e-01, -4.1114e-01, -1.9736e-01,\n",
       "                      -4.1509e-01, -8.7361e-01, -4.8336e-01, -5.5932e-01, -7.7505e-01,\n",
       "                      -4.7990e-01, -5.7850e-01, -9.7328e-01, -5.3424e-01, -6.7128e-01,\n",
       "                      -8.1941e-01, -7.6237e-01, -2.3580e-01, -7.2426e-01, -1.0740e+00,\n",
       "                      -4.4812e-01, -6.6613e-01, -5.1958e-01, -2.9523e-01, -1.4128e-01,\n",
       "                      -9.0955e-01, -9.3333e-01, -3.9344e-01, -7.4472e-01, -7.9456e-01,\n",
       "                      -3.4755e-01, -7.9469e-01, -5.8128e-01, -6.0425e-01, -4.8578e-01,\n",
       "                      -5.3537e-01, -9.1345e-01, -7.0501e-01, -5.7058e-01, -7.9211e-01,\n",
       "                      -6.7086e-01, -7.1783e-01, -7.7158e-01, -2.8725e-01, -4.0718e-01,\n",
       "                      -5.5690e-01, -3.1158e-01, -6.6827e-01, -4.1509e-01, -1.2132e+00,\n",
       "                      -2.6335e-01, -7.8012e-01, -5.0121e-01, -4.6464e-01, -5.5026e-01,\n",
       "                      -5.8129e-01, -5.9984e-01, -7.8692e-01, -1.1003e-01, -6.3965e-01,\n",
       "                      -1.1701e+00, -6.7963e-01, -7.8729e-01, -7.0878e-01, -6.2084e-01,\n",
       "                      -6.5152e-01, -1.1082e+00, -1.0892e+00, -1.2162e+00, -6.1227e-01,\n",
       "                      -9.0585e-01, -3.0221e-01, -3.2033e-01, -1.4568e-01, -5.2410e-01,\n",
       "                      -8.8136e-01, -7.9871e-01, -9.7933e-01, -8.1273e-01, -6.8036e-01,\n",
       "                      -3.6566e-01, -6.1183e-01, -5.7660e-01, -8.2722e-01, -9.0066e-01,\n",
       "                      -7.5288e-01, -5.8332e-01, -6.2057e-01, -5.9996e-01, -8.8235e-01,\n",
       "                      -3.5525e-01, -6.6926e-01, -6.6203e-01, -4.8280e-01, -6.8186e-01,\n",
       "                      -5.5176e-01, -5.8908e-01, -1.0354e+00, -3.6628e-01, -5.1621e-01,\n",
       "                      -5.5877e-01, -7.6685e-01, -6.6412e-01, -6.6827e-01, -7.9692e-01,\n",
       "                      -5.3121e-01, -7.3239e-01, -2.0373e-01, -1.9280e-01, -2.7589e-01,\n",
       "                      -6.2237e-01, -5.4963e-01, -5.7247e-01, -1.1990e+00, -8.4162e-01,\n",
       "                      -8.3704e-01, -1.0426e+00, -1.0249e+00, -7.2833e-01, -6.8283e-01,\n",
       "                      -8.2143e-01, -9.7564e-01, -9.0400e-01, -4.7188e-01, -4.7590e-01,\n",
       "                      -6.0720e-01, -6.3426e-01, -8.3003e-01, -4.9840e-01, -4.9088e-01,\n",
       "                      -8.9117e-01, -6.8896e-01, -4.1874e-01, -5.9283e-01, -9.1268e-01,\n",
       "                      -5.0299e-01, -1.0747e+00, -3.4703e-01, -1.0653e+00, -6.5797e-01,\n",
       "                      -6.2631e-01, -6.8927e-01, -7.1534e-01, -6.9307e-01, -4.9774e-01,\n",
       "                      -4.7250e-01, -4.7004e-01, -1.1848e+00, -5.0521e-01, -6.1980e-01,\n",
       "                      -6.1749e-01, -5.2364e-01, -5.9162e-01, -5.7868e-01, -7.3728e-01,\n",
       "                      -6.2265e-01, -7.1934e-01, -1.5139e+00, -1.9254e+00, -1.4228e-01,\n",
       "                       2.1421e-01,  1.1220e-01,  1.4978e+00, -1.0205e+00,  9.5560e-01,\n",
       "                      -6.4643e-01,  4.9077e-02, -1.3049e+00, -9.7845e-02,  5.4222e-02,\n",
       "                       3.8916e-01,  5.6058e-01, -2.3959e-01,  5.5766e-01,  1.3220e-01,\n",
       "                       6.0388e-01,  1.2956e+00, -9.0088e-01, -4.7052e-01, -4.5502e-01,\n",
       "                       5.6696e-01,  3.0301e+00,  2.2585e+00,  5.7692e-01,  2.9439e-01,\n",
       "                      -1.0149e-01,  8.3771e-01, -1.6596e+00, -4.4185e-01,  1.2244e+00,\n",
       "                       4.3026e-01,  2.1064e-01,  2.9987e-01, -4.0456e-01,  1.3173e+00,\n",
       "                       3.8978e-01, -1.1860e+00, -1.8582e+00,  1.0591e+00, -9.7205e-01,\n",
       "                      -6.4274e-02,  1.6942e-01, -1.0819e+00,  1.9123e+00,  1.1878e+00,\n",
       "                      -4.7713e-01, -4.8941e-01,  5.4969e-01, -2.1710e+00,  4.3872e-01,\n",
       "                       9.9910e-01, -1.0734e-01,  1.9333e-01,  3.0682e-01, -4.7584e-01,\n",
       "                       5.6915e-01,  2.0148e-01,  1.7593e-01, -1.7217e-01, -6.8650e-01,\n",
       "                       2.0760e-02,  6.4626e-01,  4.9648e-01,  2.6566e-01, -1.3741e+00,\n",
       "                      -1.3749e+00, -6.6121e-02, -4.1719e-01,  7.3080e-02, -4.2034e-03,\n",
       "                       8.6667e-01,  2.5543e-01, -5.3021e-01,  7.6960e-01,  1.3388e-01,\n",
       "                       5.5258e-01, -8.1910e-01, -7.3220e-01,  1.6918e-02, -8.6453e-01,\n",
       "                      -7.2977e-01, -4.0925e-01,  7.9137e-01,  2.4631e-01,  9.1125e-03,\n",
       "                      -1.5316e-01, -3.4249e-01,  4.1653e-01, -2.1325e-01,  9.7960e-02,\n",
       "                      -1.7505e-01,  3.1911e-01, -1.0994e+00, -8.2951e-01,  2.5420e-01,\n",
       "                      -5.6852e-01,  1.2326e+00, -5.1277e-01, -4.6766e-01, -1.0766e+00,\n",
       "                      -6.7254e-01, -6.6119e-01, -9.0028e-02, -2.6396e-01,  1.6996e-01,\n",
       "                       9.7460e-01,  1.9488e-01, -9.0315e-01,  5.3268e-01,  3.0955e-01,\n",
       "                       9.8212e-01,  2.2642e+00, -2.1425e-01, -7.9276e-01, -1.0194e+00,\n",
       "                       6.7645e-01, -1.3994e+00, -4.4244e-01,  3.7364e-01, -1.9612e-01,\n",
       "                       5.3909e-01,  2.2523e-02,  2.7134e+00, -2.3207e-02, -2.5207e-01,\n",
       "                       3.5926e-01, -6.4185e-01,  1.6336e-01, -2.0841e-01,  4.0279e-01,\n",
       "                      -7.6170e-01, -1.0762e+00, -2.3847e+00, -2.4049e-01, -4.0924e-01,\n",
       "                       6.7226e-01,  7.6143e-01, -1.2329e+00,  7.3581e-01,  3.9954e-01,\n",
       "                       1.4822e+00, -3.8179e-01,  6.8857e-01, -1.8869e-02, -9.7085e-01,\n",
       "                      -3.1857e-01,  1.1879e-01,  1.8232e-02, -5.7521e-01, -1.0369e+00,\n",
       "                      -1.0705e+00,  1.0548e-01,  2.0191e-01, -2.6105e-01,  8.7488e-01,\n",
       "                       4.3984e-01,  6.2120e-02, -1.0890e+00, -3.0086e+00, -9.3624e-01,\n",
       "                      -1.4936e+00, -4.9664e-01,  3.6080e-01,  4.7120e-01,  2.5857e-01,\n",
       "                       5.4599e-01, -7.5838e-01,  8.2713e-01, -1.2398e+00, -1.4888e-02,\n",
       "                      -5.8468e-01,  3.0717e-01, -6.2899e-01, -1.3846e+00,  2.6734e-01,\n",
       "                      -4.6694e-02,  2.7959e-01,  7.5860e-02, -3.9009e-01, -3.8177e-01,\n",
       "                      -1.4947e+00,  2.7813e-01,  2.0314e-01, -7.2588e-02,  1.0425e+00,\n",
       "                      -1.8753e-01, -4.5179e-01,  1.2663e+00,  6.9930e-01,  2.0650e-01,\n",
       "                      -3.8576e-01,  5.5846e-01,  3.5736e-01, -2.8104e-01,  1.3015e+00,\n",
       "                       2.1256e-01,  2.5199e-01, -4.2130e-01, -5.3475e-01, -2.0394e+00,\n",
       "                      -6.2523e-02,  7.3151e-01,  5.1221e-01,  1.9682e-01,  8.7494e-01,\n",
       "                       9.4987e-01,  3.3280e-01,  7.4095e-01,  1.1432e+00, -7.4118e-01,\n",
       "                       3.8540e-02,  6.0550e-02,  1.8611e+00, -4.6786e-01, -1.1383e+00,\n",
       "                      -4.5336e-01, -8.7315e-01,  3.0783e+00,  1.6732e-01, -1.6531e+00,\n",
       "                       4.1394e-01,  1.3604e+00, -5.1156e-01, -4.6917e-01,  2.4559e-01,\n",
       "                       6.4222e-02, -1.5088e-01,  2.0592e-02,  6.9111e-01,  2.3998e-01,\n",
       "                       3.9364e-01,  7.6564e-02,  3.8845e-01, -1.1525e+00, -4.1592e-01,\n",
       "                       5.4471e-02,  4.8451e-01, -1.2619e+00, -4.6108e-01,  9.4848e-02,\n",
       "                       9.7464e-01,  3.3860e-01,  1.0347e+00,  2.3897e+00, -6.7195e-01,\n",
       "                      -4.2512e-01,  9.1410e-01, -8.9175e-01, -8.0369e-01, -6.9399e-01,\n",
       "                      -6.4801e-01, -7.1644e-01,  4.4981e-01], device='cuda:0')),\n",
       "             ('gru.bias_hh_l0',\n",
       "              tensor([ 2.6187e-01,  3.2103e-01,  6.3284e-02,  7.3706e-02,  1.9005e-01,\n",
       "                       3.0566e-01,  3.4617e-01,  1.2537e-01,  9.6975e-02,  4.3252e-02,\n",
       "                       1.8427e-01,  8.4138e-02,  1.4647e-01,  8.0795e-02,  3.7994e-02,\n",
       "                       9.3688e-02,  6.9393e-02,  4.9904e-02,  1.2491e-01,  1.9643e-01,\n",
       "                       3.3358e-01,  5.4283e-02, -4.0967e-02,  1.4362e-01,  1.1565e+00,\n",
       "                       2.9741e-01,  2.6600e-01,  2.3430e-01,  5.7678e-02,  6.0837e-02,\n",
       "                       2.2683e-01,  4.5374e-02,  2.4172e-01,  5.6520e-03,  2.1430e-01,\n",
       "                       1.9557e-01,  2.0245e-01,  2.9390e-01, -2.5564e-02,  2.5085e-01,\n",
       "                       1.7381e-01,  1.1525e-01,  1.7322e-01,  1.0263e-03,  1.6798e-01,\n",
       "                       9.9554e-02, -3.5086e-01,  9.4093e-02,  1.4416e-01,  2.4249e-01,\n",
       "                       5.2505e-01,  7.9429e-01,  2.1765e-01,  5.0865e-02,  3.0295e-01,\n",
       "                       1.2196e-01,  1.0463e-01,  1.5908e-01,  5.4302e-02,  1.6833e-01,\n",
       "                       6.5538e-02,  1.8441e-01,  4.5777e-02,  1.2023e-01,  8.7052e-02,\n",
       "                       1.1598e-01,  1.0167e-01,  2.0462e-01,  2.2666e-01, -1.9734e-03,\n",
       "                       1.3124e-01,  8.6718e-02,  2.7920e-01,  1.5035e-01,  9.0818e-02,\n",
       "                       2.1231e-01,  1.4939e-01,  1.2685e-01,  5.8165e-02,  1.7993e-01,\n",
       "                       2.0639e-01,  6.7672e-03,  2.4966e-01,  1.6858e-01,  1.1096e-01,\n",
       "                       1.5333e-01,  1.4305e-01,  1.3515e-01,  8.4678e-02,  2.0471e-01,\n",
       "                       2.6112e-02,  1.4323e-01,  1.3602e-01,  1.1443e-01,  7.4875e-02,\n",
       "                       1.3209e-01,  1.2422e-01,  1.1772e-01,  2.0282e-01,  1.7241e-01,\n",
       "                       6.2718e-02,  3.4108e-02,  1.2429e-01,  2.2136e-01,  8.6991e-02,\n",
       "                       1.5070e-02,  9.4040e-02,  1.4358e-01,  1.1527e-01,  6.9165e-02,\n",
       "                       1.8617e-02,  1.4886e-01,  1.2002e-01,  2.0847e-01,  3.7605e-01,\n",
       "                       7.2733e-02,  1.2561e-01,  5.2396e-01,  1.8047e-01,  2.6111e-01,\n",
       "                       1.5206e-01,  4.0350e-02,  4.9784e-02,  1.3964e-01,  7.5787e-02,\n",
       "                       3.5408e-01,  2.6665e-01,  1.6166e-01,  7.6069e-02,  7.3609e-02,\n",
       "                       7.5622e-02,  1.1060e-01,  1.4798e-01,  1.8952e-02,  6.0677e-02,\n",
       "                       3.8415e-01,  1.9678e-01,  1.0486e-01,  1.6298e-01,  3.3764e-02,\n",
       "                       3.9030e-01,  2.8221e-02,  7.9875e-02,  2.0437e-01, -4.2434e-02,\n",
       "                       7.7439e-03,  1.6468e-01,  2.6807e-02,  5.9537e-02,  9.2394e-02,\n",
       "                       2.0273e-02,  1.1340e-01,  6.1042e-02,  1.4001e-01,  1.3158e-01,\n",
       "                       1.1233e-01,  2.0194e-01,  8.9315e-03,  1.5019e-01,  2.7612e-01,\n",
       "                       1.5187e-01,  1.2238e+00,  1.9115e-01,  1.0569e-01,  4.0416e-01,\n",
       "                       1.0388e-01,  1.3252e-01,  1.1296e-01,  1.1107e-01,  5.9181e-02,\n",
       "                       1.2697e-01,  8.0195e-02,  3.2976e-02,  1.1761e-01,  1.9262e-01,\n",
       "                       1.7179e-01,  2.0289e-01,  2.0377e-01,  1.8363e-01,  6.1048e-02,\n",
       "                       1.4500e-01,  1.2096e-01,  3.7345e-02,  1.6649e-01,  3.1613e-02,\n",
       "                      -2.3193e-02,  5.8024e-02,  2.4859e-01,  1.3895e-01,  1.7732e-01,\n",
       "                       1.4171e-01,  1.1329e-01,  1.4278e-01,  2.2338e-01,  1.3151e-01,\n",
       "                       1.8831e-01,  2.3225e-01,  4.2969e-01,  1.7205e-01, -7.0202e-03,\n",
       "                       2.2792e-02,  2.8709e-01,  3.6450e-01,  1.0289e-01,  1.7299e-01,\n",
       "                       2.1147e-01,  6.4569e-03,  1.2168e-01,  1.4186e-01,  5.7999e-02,\n",
       "                       9.7232e-02,  2.5873e-01,  7.2911e-02,  5.8889e-02,  1.3155e-01,\n",
       "                       2.8540e-01,  2.0367e-01,  1.8400e-01,  7.2165e-03, -5.3078e-02,\n",
       "                       5.4056e-01,  3.1229e-02,  2.8447e-01,  1.1449e-01,  1.8251e-01,\n",
       "                       5.6770e-02,  1.1300e-01,  7.8741e-02,  1.0710e-01,  1.1309e-01,\n",
       "                       1.4639e-01,  1.2225e-01,  1.3179e-01,  1.5742e-01,  1.7114e-01,\n",
       "                       1.3333e-01,  1.9164e-01,  1.0062e-01,  1.6657e-01,  1.7947e-01,\n",
       "                       1.9095e-01,  7.4045e-02,  6.0257e-02,  1.8499e-01,  1.3351e-01,\n",
       "                       2.1307e-01,  4.8526e-01,  8.0098e-02,  5.9501e-02,  8.3809e-02,\n",
       "                       1.7451e-01,  2.7589e-01,  1.7056e-01,  3.5561e-01,  2.0830e-01,\n",
       "                       1.5195e-01, -1.0930e+00, -7.0402e-01, -7.9280e-01, -4.4878e-01,\n",
       "                      -8.2522e-01, -9.8743e-01, -9.7476e-01, -8.3948e-01, -3.8897e-01,\n",
       "                      -8.0296e-01, -5.6713e-01, -7.7476e-01, -5.3245e-01, -6.9283e-01,\n",
       "                      -7.1075e-01, -8.1386e-01, -7.2763e-01, -7.0240e-01, -4.7692e-01,\n",
       "                      -8.1786e-01, -6.6725e-01, -4.5489e-01,  2.3780e-02, -5.5579e-01,\n",
       "                      -6.9774e-01, -6.2120e-01, -6.1619e-01, -7.7946e-01, -3.0287e-01,\n",
       "                      -4.0557e-01, -4.4108e-01, -7.5676e-01, -5.9404e-01, -1.5503e-01,\n",
       "                      -7.7055e-01, -7.1924e-01, -7.1023e-01, -4.0976e-01, -8.1563e-01,\n",
       "                      -5.1831e-01, -6.4527e-01, -4.5796e-01, -5.8245e-01, -4.0315e-01,\n",
       "                      -3.4082e-01, -6.2833e-01, -9.5156e-01, -4.7837e-01, -9.6899e-01,\n",
       "                      -9.9040e-01, -8.2765e-01, -5.3152e-01, -8.3375e-01, -1.0701e+00,\n",
       "                      -6.6816e-01, -9.2143e-01, -8.1240e-01, -6.3320e-01, -7.1299e-01,\n",
       "                      -9.2369e-01, -6.2839e-01, -8.6909e-01, -7.9435e-01, -7.1948e-01,\n",
       "                      -6.1094e-01, -8.5790e-01, -4.7482e-01, -6.9096e-01, -5.3557e-01,\n",
       "                      -3.1509e-01, -3.1156e-01, -4.1406e-01, -6.2179e-01, -8.2094e-01,\n",
       "                      -5.2615e-01, -7.2407e-01, -5.7490e-01, -6.8453e-01, -5.8146e-01,\n",
       "                      -4.5340e-01, -6.2865e-01,  1.7835e-01, -4.3484e-01, -9.3757e-01,\n",
       "                      -1.0847e+00, -8.5668e-01, -4.1536e-01, -8.8081e-01, -1.0595e+00,\n",
       "                      -8.1011e-01, -2.7009e-01, -5.1299e-01, -3.1352e-01, -6.8029e-01,\n",
       "                      -5.5173e-01, -7.5253e-01, -9.2347e-01, -3.4331e-01, -6.0494e-01,\n",
       "                      -3.6355e-01, -9.8772e-01, -7.4823e-01, -3.9596e-01, -2.1460e-01,\n",
       "                      -4.3741e-01, -8.5419e-01, -4.4217e-01, -5.0010e-01, -8.0733e-01,\n",
       "                      -5.7281e-01, -5.3987e-01, -9.3696e-01, -6.1487e-01, -5.7427e-01,\n",
       "                      -8.6079e-01, -7.6118e-01, -1.9290e-01, -7.6594e-01, -1.0460e+00,\n",
       "                      -4.1019e-01, -6.9032e-01, -5.2282e-01, -3.5174e-01, -2.4416e-01,\n",
       "                      -9.4054e-01, -9.1010e-01, -3.6704e-01, -7.2665e-01, -7.7340e-01,\n",
       "                      -4.5507e-01, -7.9549e-01, -6.3376e-01, -6.6722e-01, -5.1133e-01,\n",
       "                      -4.8740e-01, -1.0137e+00, -8.0683e-01, -5.6110e-01, -8.6868e-01,\n",
       "                      -7.6180e-01, -6.6064e-01, -7.4142e-01, -3.2940e-01, -4.5442e-01,\n",
       "                      -6.5430e-01, -3.3312e-01, -6.4487e-01, -4.2215e-01, -1.1056e+00,\n",
       "                      -2.4281e-01, -7.6370e-01, -5.1470e-01, -5.4973e-01, -4.8168e-01,\n",
       "                      -6.2388e-01, -5.8296e-01, -7.3017e-01, -9.9647e-02, -5.7412e-01,\n",
       "                      -1.0921e+00, -6.9267e-01, -7.5416e-01, -7.4145e-01, -7.3950e-01,\n",
       "                      -6.3829e-01, -1.0785e+00, -1.0715e+00, -1.1240e+00, -6.6114e-01,\n",
       "                      -1.0076e+00, -2.5167e-01, -2.2283e-01, -1.1378e-01, -5.0499e-01,\n",
       "                      -9.1300e-01, -6.9275e-01, -1.0034e+00, -7.8658e-01, -7.0125e-01,\n",
       "                      -3.1984e-01, -6.8020e-01, -6.5128e-01, -8.2897e-01, -8.0901e-01,\n",
       "                      -8.0594e-01, -5.5876e-01, -5.9139e-01, -6.0257e-01, -9.1091e-01,\n",
       "                      -3.9195e-01, -6.1659e-01, -6.5133e-01, -4.9018e-01, -6.0285e-01,\n",
       "                      -6.7091e-01, -6.5887e-01, -1.0779e+00, -4.0177e-01, -5.1961e-01,\n",
       "                      -4.4014e-01, -7.0447e-01, -7.0098e-01, -6.6717e-01, -7.3569e-01,\n",
       "                      -6.1928e-01, -7.5148e-01, -2.0975e-01, -2.2691e-01, -2.3501e-01,\n",
       "                      -5.6871e-01, -5.8229e-01, -5.6999e-01, -1.1750e+00, -8.2919e-01,\n",
       "                      -8.2698e-01, -1.1364e+00, -1.1057e+00, -6.7164e-01, -7.4824e-01,\n",
       "                      -7.5735e-01, -9.8918e-01, -8.5924e-01, -5.5730e-01, -4.2026e-01,\n",
       "                      -5.7411e-01, -5.4521e-01, -7.8446e-01, -4.9259e-01, -5.4299e-01,\n",
       "                      -8.5369e-01, -5.9160e-01, -4.1912e-01, -6.3612e-01, -9.1744e-01,\n",
       "                      -4.8865e-01, -9.7752e-01, -3.8656e-01, -1.1490e+00, -7.7900e-01,\n",
       "                      -6.7287e-01, -6.9981e-01, -6.5415e-01, -6.3260e-01, -4.7319e-01,\n",
       "                      -4.9776e-01, -4.3668e-01, -1.2743e+00, -4.9262e-01, -6.0880e-01,\n",
       "                      -5.6283e-01, -5.1619e-01, -6.9071e-01, -6.0807e-01, -6.7624e-01,\n",
       "                      -6.1200e-01, -7.1566e-01, -8.1364e-01, -1.0515e+00, -8.1366e-02,\n",
       "                       1.2468e-01, -9.9213e-02,  6.0772e-01, -3.7115e-01,  3.7118e-01,\n",
       "                      -5.2598e-01, -5.3122e-02, -7.1599e-01, -3.4869e-01,  1.1926e-01,\n",
       "                       5.4806e-02,  3.3656e-01, -4.4090e-02,  4.2441e-01, -1.6737e-01,\n",
       "                       3.3805e-01,  5.4052e-01, -4.4274e-01,  3.0409e-02, -1.5854e-01,\n",
       "                       3.4786e-01,  1.3213e+00,  1.2863e+00,  1.0117e-01,  2.1766e-01,\n",
       "                       5.3780e-02,  3.7896e-01, -9.6590e-01, -3.4010e-01,  2.6526e-01,\n",
       "                       1.2823e-01,  1.0519e-02, -1.3796e-01, -9.7009e-02,  5.8687e-01,\n",
       "                       8.6810e-02, -6.5510e-01, -1.1669e+00,  5.0948e-01, -3.1824e-01,\n",
       "                      -5.9333e-04,  1.9302e-01, -6.0751e-01,  1.4340e+00,  7.1042e-01,\n",
       "                      -1.1524e-01, -1.6081e-01,  4.1981e-02, -1.0069e+00,  4.4835e-02,\n",
       "                       6.7644e-01,  2.9567e-01,  2.0384e-01,  7.8667e-02, -3.5109e-01,\n",
       "                       6.1939e-01,  1.1388e-01,  1.6035e-01, -1.7169e-01, -3.2400e-01,\n",
       "                      -2.2118e-02,  1.6312e-01,  5.4409e-01,  1.2571e-01, -5.9604e-01,\n",
       "                      -8.7973e-01, -2.6616e-02, -4.1234e-01,  1.0089e-01,  2.2222e-01,\n",
       "                       6.3788e-01,  2.0848e-01, -4.3338e-01,  7.5461e-02,  1.3947e-01,\n",
       "                       1.6801e-01, -1.9569e-01, -8.8284e-02,  1.2357e-01, -1.9224e-01,\n",
       "                      -5.9557e-02, -3.0452e-01,  3.2897e-01,  1.4893e-01, -3.4368e-01,\n",
       "                       9.4240e-02, -2.4873e-02,  2.4246e-01,  1.6701e-01,  7.3016e-02,\n",
       "                      -2.9789e-01,  1.9446e-01, -5.1616e-01, -3.8861e-01,  4.0696e-01,\n",
       "                      -2.9764e-01,  6.2402e-01, -5.9284e-01, -3.6955e-01, -5.1916e-01,\n",
       "                      -7.0336e-02, -2.4989e-01, -1.2445e-01, -2.8434e-01,  1.5345e-01,\n",
       "                       5.1876e-01,  2.8484e-02, -4.9037e-01,  1.4738e-01,  3.3154e-01,\n",
       "                       3.4474e-01,  1.1136e+00, -2.8408e-01, -4.5048e-01, -1.7278e-01,\n",
       "                       2.6134e-02, -6.2999e-01,  1.8083e-02,  3.4794e-01, -9.6357e-02,\n",
       "                       4.5717e-01, -2.2550e-01,  1.4777e+00, -2.3510e-02,  3.7358e-02,\n",
       "                       4.3252e-02, -3.9421e-02,  2.7433e-01, -2.2639e-01,  2.4214e-01,\n",
       "                      -3.7588e-01, -4.4363e-01, -1.0705e+00, -2.3415e-01, -1.4090e-02,\n",
       "                       3.3358e-01, -2.2189e-02, -3.3343e-01,  2.9678e-01,  2.3718e-01,\n",
       "                       7.9241e-01, -2.3364e-01,  3.8183e-01,  1.4325e-02, -6.3361e-01,\n",
       "                      -4.1566e-01,  1.3259e-01,  1.2015e-01, -6.9458e-02, -3.7457e-01,\n",
       "                      -5.5744e-01, -5.7865e-02,  1.9358e-01, -9.6524e-02,  2.6959e-01,\n",
       "                      -8.6351e-02, -2.1808e-01, -5.5879e-01, -1.5483e+00, -2.3221e-01,\n",
       "                      -7.7246e-01, -6.2374e-02, -5.1357e-02,  1.1993e-01,  2.5368e-01,\n",
       "                       2.9954e-01, -3.6831e-01,  3.7313e-01, -6.0489e-01, -1.2940e-01,\n",
       "                      -3.7636e-01,  9.0675e-02, -2.2066e-01, -7.7505e-01,  2.2792e-01,\n",
       "                       2.4962e-01,  1.4237e-01, -1.1437e-01, -2.8223e-01, -2.7480e-01,\n",
       "                      -7.3870e-01,  2.0630e-01,  9.9468e-02,  1.2945e-02,  5.5885e-01,\n",
       "                       5.0405e-02, -9.5901e-02,  6.2303e-01,  3.7593e-01,  2.7647e-01,\n",
       "                      -1.4755e-01,  4.5990e-01,  2.1209e-01, -1.0738e-01,  3.3185e-01,\n",
       "                       1.6291e-01,  1.6032e-01, -1.7876e-01, -2.3667e-01, -1.2139e+00,\n",
       "                      -1.5231e-01,  2.1607e-01,  2.8304e-01,  3.1112e-02,  4.7573e-01,\n",
       "                       4.7710e-01,  1.1771e-01,  3.0731e-01,  6.4460e-01, -3.1878e-01,\n",
       "                      -1.7665e-01,  1.7621e-01,  9.8442e-01, -1.8479e-01, -5.0245e-01,\n",
       "                      -1.7843e-01, -4.8893e-01,  1.0429e+00,  1.5778e-01, -8.5804e-01,\n",
       "                       2.3902e-01,  7.9945e-01, -1.9853e-01, -1.6979e-01,  1.5496e-01,\n",
       "                      -2.3219e-02, -5.0024e-02,  9.4430e-02,  2.6302e-01,  1.8906e-01,\n",
       "                       2.2189e-01,  4.3481e-03,  2.8589e-01, -5.3086e-01, -2.4683e-01,\n",
       "                       5.8791e-02,  1.0580e-01, -4.9000e-01, -2.4694e-01,  1.0176e-01,\n",
       "                       4.7945e-01,  2.2180e-01,  8.9672e-01,  1.1869e+00, -4.3908e-01,\n",
       "                      -1.4649e-01,  4.8993e-01, -3.3637e-01, -5.5427e-01, -1.6734e-01,\n",
       "                      -1.7870e-01, -1.8386e-01,  1.7513e-01], device='cuda:0'))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\n",
    "    'model.pt', map_location=lambda storage, loc: storage)\n",
    "\n",
    "encoder_sd = checkpoint['en']\n",
    "decoder_sd = checkpoint['de']\n",
    "\n",
    "encoder1.load_state_dict(encoder_sd)\n",
    "\n",
    "attn_decoder1.load_state_dict(decoder_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-0.8420, -1.2183,  1.1326,  ..., -0.1625,  1.1364, -0.9973],\n",
       "                      [ 0.4027,  1.2902,  0.0661,  ...,  0.3133,  1.5310, -1.3547],\n",
       "                      [ 0.2920, -0.5148,  0.1965,  ..., -0.2824, -0.1273,  1.3941],\n",
       "                      ...,\n",
       "                      [-0.2700,  0.4899, -0.2470,  ..., -0.4459, -0.4455,  0.2902],\n",
       "                      [ 0.5684,  0.1471,  1.4874,  ...,  0.8377, -0.2123, -0.3047],\n",
       "                      [-0.3760,  1.7969, -2.2950,  ..., -1.4813,  1.1347,  0.1509]],\n",
       "                     device='cuda:0')),\n",
       "             ('gru.weight_ih_l0',\n",
       "              tensor([[ 4.4572e-03, -5.0456e-03,  6.0365e-03,  ...,  5.9608e-05,\n",
       "                        1.0817e-02, -3.5430e-02],\n",
       "                      [ 3.8247e-02, -5.7775e-02,  4.8638e-02,  ...,  3.2293e-02,\n",
       "                       -5.9803e-02, -3.6782e-02],\n",
       "                      [-5.8603e-02, -1.4985e-02, -4.2834e-02,  ...,  4.3941e-02,\n",
       "                        3.1431e-02,  5.3007e-02],\n",
       "                      ...,\n",
       "                      [ 3.2841e-02,  1.7467e-02,  4.8133e-02,  ...,  4.0012e-02,\n",
       "                       -4.6768e-02,  3.6519e-02],\n",
       "                      [-9.9080e-03, -4.7580e-02,  3.0534e-02,  ..., -5.6467e-02,\n",
       "                        5.5955e-02,  1.8242e-02],\n",
       "                      [-2.4322e-02,  1.8166e-02,  3.2162e-03,  ...,  2.3583e-02,\n",
       "                        5.1767e-02, -5.4964e-02]], device='cuda:0')),\n",
       "             ('gru.weight_hh_l0',\n",
       "              tensor([[ 6.0876e-03,  7.4582e-03, -7.7474e-03,  ...,  1.3848e-02,\n",
       "                        4.3307e-02, -2.5403e-02],\n",
       "                      [-4.8840e-02,  7.8446e-03,  2.4825e-05,  ...,  3.1849e-02,\n",
       "                        5.6291e-02,  1.0944e-02],\n",
       "                      [-1.3971e-02, -3.4592e-02,  2.5075e-02,  ...,  1.0570e-02,\n",
       "                        3.9248e-02, -5.4910e-03],\n",
       "                      ...,\n",
       "                      [ 1.5007e-02, -4.5585e-02,  3.9770e-02,  ..., -2.8522e-02,\n",
       "                       -2.8900e-02,  6.0226e-02],\n",
       "                      [ 2.4671e-02,  5.9615e-02, -4.8172e-02,  ...,  5.5262e-02,\n",
       "                       -5.5132e-02,  5.9189e-02],\n",
       "                      [ 5.4404e-02,  5.8022e-02,  4.0446e-02,  ..., -5.4931e-03,\n",
       "                        2.3016e-02, -2.3653e-02]], device='cuda:0')),\n",
       "             ('gru.bias_ih_l0',\n",
       "              tensor([ 2.0096e-02,  2.9415e-02, -6.2044e-02,  6.5421e-03,  3.7361e-02,\n",
       "                      -5.2888e-02,  5.7976e-02, -5.0818e-02,  5.1190e-03, -1.7458e-02,\n",
       "                      -3.6978e-02, -5.2871e-02, -1.1628e-02, -4.2141e-02, -1.6986e-02,\n",
       "                      -5.5331e-02, -5.1427e-02, -7.1931e-03,  3.6924e-02, -4.7742e-03,\n",
       "                      -5.4120e-03, -3.1200e-02, -1.4531e-02,  2.1296e-02,  4.8063e-02,\n",
       "                      -4.7385e-02,  4.3017e-02,  2.9056e-02, -5.6477e-03, -2.5014e-02,\n",
       "                       5.9019e-02, -3.8546e-03,  2.5218e-02,  4.3552e-02, -1.7323e-02,\n",
       "                      -5.5825e-02,  5.1078e-03,  2.3122e-03, -1.2991e-02,  4.5039e-02,\n",
       "                      -4.6033e-02,  5.4547e-02,  5.1753e-02,  2.0341e-02,  5.1257e-02,\n",
       "                      -1.7123e-02, -5.6232e-02, -8.3619e-03, -6.0292e-02,  6.1947e-02,\n",
       "                       5.3007e-03, -4.6458e-02, -5.5734e-02,  3.1925e-02, -1.0690e-02,\n",
       "                      -4.2193e-02, -2.1742e-02,  9.9305e-03,  1.2292e-02,  3.0118e-03,\n",
       "                       8.2168e-03, -5.5829e-02, -2.6060e-02,  5.9292e-02, -2.4043e-02,\n",
       "                       2.6336e-02,  4.7101e-02, -3.2123e-02,  3.0507e-02,  5.2808e-03,\n",
       "                      -1.5727e-02, -5.3264e-02,  1.2635e-02,  1.7773e-02,  4.9420e-02,\n",
       "                       3.7789e-03, -6.1281e-02, -3.7197e-02,  4.7664e-02,  1.2268e-02,\n",
       "                       3.3573e-02,  5.5676e-05, -1.6509e-02, -3.8217e-02,  3.7091e-02,\n",
       "                      -1.5147e-02, -2.6298e-02,  2.4939e-02, -3.0279e-02, -5.3953e-02,\n",
       "                      -4.1478e-02, -5.1876e-02, -2.2994e-02, -2.8063e-03, -6.8206e-04,\n",
       "                      -5.4777e-02, -1.0873e-02,  5.9883e-03, -3.2612e-02,  2.6215e-02,\n",
       "                      -3.9639e-02, -5.1900e-02,  2.2240e-02,  3.5215e-02,  3.5070e-02,\n",
       "                       5.2383e-02, -5.1602e-02,  1.7247e-02, -4.7039e-02, -3.5880e-02,\n",
       "                       3.0891e-03, -5.5424e-02,  5.3496e-02,  1.2178e-03,  7.2890e-03,\n",
       "                       2.0169e-02, -2.0722e-02,  5.1612e-02, -1.6912e-02,  1.7786e-02,\n",
       "                       2.0641e-02,  6.1784e-02,  1.4263e-02,  3.1198e-02,  8.0659e-03,\n",
       "                      -5.9783e-03,  2.6373e-02, -5.1380e-02,  2.4831e-02, -3.3380e-02,\n",
       "                       1.8902e-02, -5.0988e-02,  3.7415e-02, -2.0429e-02,  1.8212e-02,\n",
       "                       2.5403e-02,  3.6904e-02, -5.8935e-02, -2.6546e-02, -3.5355e-02,\n",
       "                       1.2456e-02,  3.3438e-02, -7.5918e-04,  4.0746e-02, -3.4777e-02,\n",
       "                       5.4317e-02, -4.5191e-02, -5.8874e-03, -1.5637e-03, -2.1817e-02,\n",
       "                      -5.8551e-02,  4.4872e-02,  6.2200e-02,  2.3216e-03,  3.0224e-02,\n",
       "                       5.6537e-03, -2.6754e-02, -6.0030e-02,  2.0371e-02, -5.3270e-03,\n",
       "                       4.2131e-02, -4.4109e-02,  4.4260e-02, -6.0135e-02,  1.8404e-02,\n",
       "                       2.1592e-02,  4.2340e-02, -6.6448e-03,  3.6880e-02, -5.6428e-02,\n",
       "                       3.9638e-02,  2.7959e-02,  6.0166e-02, -3.4865e-02,  5.0073e-02,\n",
       "                      -4.3382e-02,  3.7127e-02,  6.2300e-02, -3.3919e-02,  1.1478e-02,\n",
       "                      -3.3312e-02,  1.6754e-02, -3.3614e-02,  1.1590e-02, -3.9846e-02,\n",
       "                      -7.7903e-03,  3.7990e-02, -4.8620e-02,  5.5825e-02,  3.5138e-02,\n",
       "                      -1.0396e-02,  5.3341e-02,  4.6991e-02, -4.4360e-02, -4.7144e-02,\n",
       "                       4.9066e-03, -6.0959e-02,  1.0849e-02, -4.8882e-02,  3.5472e-02,\n",
       "                      -4.7254e-02, -4.1071e-02,  4.8441e-02,  6.3115e-03,  3.5708e-02,\n",
       "                      -1.1075e-02,  1.2236e-02, -5.4329e-02,  2.3402e-02,  5.6584e-03,\n",
       "                      -2.0587e-02, -4.0605e-03, -7.0075e-03, -8.1436e-03, -2.9173e-03,\n",
       "                       4.8667e-02,  4.6087e-03, -6.0305e-02, -5.3942e-02, -2.7816e-02,\n",
       "                      -2.8948e-02, -4.7987e-02, -4.9246e-02,  2.7595e-02, -5.4997e-02,\n",
       "                      -1.1611e-02,  4.5166e-02, -2.2145e-02,  6.0448e-03, -7.8745e-03,\n",
       "                       3.9773e-02, -3.4549e-03, -4.3684e-02, -4.2066e-02,  5.6918e-02,\n",
       "                       1.3504e-02, -1.9228e-02,  3.3669e-02, -4.3021e-02,  2.7493e-02,\n",
       "                       1.3801e-02, -1.3714e-02, -6.0400e-02, -1.8539e-02,  7.7790e-03,\n",
       "                      -2.5096e-02,  2.5523e-03,  5.1240e-02, -3.4458e-02,  6.1839e-02,\n",
       "                       3.5399e-02,  3.2759e-02,  4.8422e-03, -5.0969e-02, -4.9148e-02,\n",
       "                      -4.3999e-02,  1.8734e-02,  6.6544e-03,  6.5585e-03, -4.8278e-03,\n",
       "                      -4.9055e-02,  4.0448e-02,  3.4838e-02, -4.3350e-02, -6.1027e-02,\n",
       "                      -3.8093e-02, -5.7718e-02, -4.3591e-02, -9.9330e-03, -1.1561e-02,\n",
       "                       3.0270e-02,  4.3727e-02,  1.9646e-02, -5.3434e-02,  3.4893e-02,\n",
       "                       3.1924e-03,  1.4447e-02, -4.8191e-03,  4.0911e-03,  4.2934e-02,\n",
       "                       6.1951e-02, -4.2859e-02, -4.7977e-02, -3.3086e-02, -2.2963e-02,\n",
       "                       2.4510e-02, -1.0118e-02,  1.4161e-02,  4.2612e-02, -2.4520e-02,\n",
       "                       3.1741e-02,  3.7337e-02,  2.0745e-02,  5.6270e-02,  6.1850e-02,\n",
       "                       1.3622e-02,  6.0856e-02, -5.2719e-02, -4.3651e-02, -2.8337e-02,\n",
       "                       6.2151e-02, -4.9365e-02,  5.4192e-02,  1.7615e-02,  1.3510e-02,\n",
       "                      -4.5695e-02, -1.4434e-03, -1.7989e-02,  4.8902e-03, -6.7681e-03,\n",
       "                       2.5716e-02, -1.7853e-02, -5.9285e-02,  3.3619e-02,  2.8270e-02,\n",
       "                       2.0869e-02,  5.6042e-02,  7.5444e-03,  4.6146e-04, -6.1269e-02,\n",
       "                      -4.0415e-03,  2.1937e-02,  9.5335e-03, -4.6256e-02,  4.5105e-02,\n",
       "                      -4.2419e-02, -4.8307e-03, -1.0197e-02, -4.9715e-02,  1.4080e-02,\n",
       "                       1.5813e-02,  2.9139e-02,  1.1698e-02,  7.2104e-03, -1.4631e-02,\n",
       "                      -4.7104e-02, -4.8921e-02,  5.7827e-02,  1.7972e-02,  3.7216e-02,\n",
       "                       6.4116e-03,  8.7116e-03, -1.6771e-02,  3.2196e-02, -4.6458e-02,\n",
       "                      -5.7757e-02, -5.6602e-02,  5.6587e-02, -3.0623e-02,  4.8065e-02,\n",
       "                       3.8795e-03,  3.9892e-02, -2.3934e-02, -4.9011e-02, -2.6328e-02,\n",
       "                       2.9452e-02,  7.4872e-03,  2.1997e-03,  1.3636e-02, -1.4485e-02,\n",
       "                       5.3608e-02, -2.2885e-02, -4.2349e-02,  3.4107e-02,  1.4586e-02,\n",
       "                       2.2209e-02,  1.7766e-02,  2.0797e-02,  4.4615e-03,  3.5207e-02,\n",
       "                      -5.4156e-03, -5.1803e-02, -2.5099e-02,  3.8165e-02, -6.3242e-03,\n",
       "                       3.5127e-02,  1.9166e-02,  7.2520e-05, -4.8177e-03,  3.9709e-02,\n",
       "                      -5.5581e-03,  3.0630e-02,  3.8912e-02,  2.1893e-02, -1.5407e-02,\n",
       "                       4.8446e-02,  4.0093e-02,  5.5418e-02, -2.6621e-02,  2.6411e-02,\n",
       "                       3.6108e-02,  3.2197e-02,  3.7693e-02,  3.5800e-02, -3.0273e-02,\n",
       "                      -1.7750e-02, -3.6879e-02,  5.3193e-02,  5.3909e-03, -2.1080e-02,\n",
       "                       5.1963e-02,  1.8143e-02,  1.3334e-02, -1.8344e-02, -3.6546e-02,\n",
       "                       5.8881e-02,  3.0561e-02, -2.6391e-02, -3.6362e-02, -1.9359e-02,\n",
       "                       2.2708e-02,  3.6511e-02, -2.6808e-02, -4.9252e-02, -8.7718e-03,\n",
       "                       1.3651e-02,  4.5383e-02,  4.1524e-02, -3.5982e-02, -5.7947e-02,\n",
       "                       3.2599e-02, -5.8567e-02, -5.0598e-02, -5.3728e-02, -4.1729e-02,\n",
       "                       1.4013e-03, -2.0029e-02,  7.1825e-03,  2.5291e-02,  7.5644e-03,\n",
       "                      -1.1856e-02,  2.8837e-02, -2.9206e-02, -6.1319e-02, -5.5412e-02,\n",
       "                       3.2919e-02,  1.5703e-02, -1.5950e-02, -5.8636e-02,  1.8778e-02,\n",
       "                      -2.7285e-02, -2.4521e-02,  1.7111e-02,  5.7141e-02,  5.3428e-02,\n",
       "                      -1.9260e-02, -4.8019e-02,  5.9130e-02, -8.3122e-03, -5.8189e-02,\n",
       "                      -3.3980e-02, -4.5234e-02,  4.0507e-02, -3.8796e-02,  2.1908e-02,\n",
       "                      -4.9737e-02,  2.7212e-02, -6.3257e-02, -2.1866e-02, -6.1328e-02,\n",
       "                      -1.0001e-03, -7.2432e-03,  4.9775e-02,  2.9303e-02, -5.4044e-02,\n",
       "                      -8.6428e-03,  5.2729e-02,  5.8841e-02,  2.5223e-02, -2.7803e-02,\n",
       "                      -1.6676e-02, -6.0079e-02,  8.1031e-03, -4.6884e-02, -4.8468e-02,\n",
       "                       8.7942e-03, -1.8952e-02, -9.7327e-03,  2.4678e-02,  2.4628e-02,\n",
       "                       5.8370e-03,  2.4725e-02, -5.5209e-02,  2.9576e-02, -5.8872e-02,\n",
       "                      -3.6873e-02,  3.2531e-02,  2.7081e-02,  1.2190e-02, -3.5945e-02,\n",
       "                       5.0991e-02, -3.7091e-02,  1.4844e-02,  5.0855e-02,  4.9985e-02,\n",
       "                       2.8710e-02, -4.3360e-02,  1.9157e-02,  5.3010e-02,  5.5675e-02,\n",
       "                      -5.2218e-02,  4.9299e-03, -6.4034e-03,  3.5437e-02, -4.3342e-02,\n",
       "                      -3.1845e-02, -4.2635e-02, -2.1572e-02, -5.1950e-02, -5.5706e-02,\n",
       "                       3.2960e-02, -4.6514e-04,  2.7240e-02, -1.9592e-02, -5.9274e-02,\n",
       "                      -2.6134e-02,  6.1500e-02, -1.3993e-02,  1.0113e-03,  8.5474e-03,\n",
       "                       4.3414e-02, -2.9086e-02, -4.9166e-02,  5.5720e-02,  6.9541e-03,\n",
       "                       4.4202e-02, -3.8351e-02,  6.4871e-03,  2.4161e-02, -1.0533e-02,\n",
       "                       4.9639e-02, -1.5576e-02,  4.9914e-02,  2.9564e-02, -1.7752e-02,\n",
       "                       4.1640e-02,  5.0571e-02, -3.1590e-02,  3.9627e-02,  8.9790e-03,\n",
       "                       1.3599e-04,  2.5869e-02, -4.2984e-02,  2.2894e-02,  4.8212e-02,\n",
       "                      -3.9780e-02, -4.1897e-02,  3.8581e-02, -5.7331e-02,  4.6123e-02,\n",
       "                       8.1606e-03, -5.5633e-03,  6.9112e-03,  1.4710e-02, -1.5743e-02,\n",
       "                      -3.6998e-02,  1.5113e-03, -3.6414e-02, -4.2453e-02, -4.8673e-02,\n",
       "                       1.7153e-03, -4.5699e-02,  6.9542e-03, -5.4438e-02, -4.2670e-02,\n",
       "                       1.4624e-02, -5.5810e-02, -4.8931e-02, -5.4981e-02,  6.5948e-03,\n",
       "                       1.1142e-02,  3.1110e-02,  5.8154e-02,  1.2086e-02,  5.8200e-02,\n",
       "                      -2.7075e-02,  3.8810e-02,  4.4749e-02,  3.3274e-02,  1.3168e-02,\n",
       "                      -6.4539e-02,  8.2117e-04, -1.8078e-02,  1.1153e-02, -2.9206e-02,\n",
       "                       5.8792e-02, -4.4264e-02,  1.0987e-03,  9.6464e-03, -3.7999e-02,\n",
       "                      -4.8801e-02,  5.4014e-02, -5.2845e-02, -3.8031e-02,  5.6448e-02,\n",
       "                       2.2155e-02,  4.8199e-02, -2.1721e-02,  3.2219e-02,  4.6283e-02,\n",
       "                       3.7484e-02, -3.1918e-02, -2.4995e-02, -9.4389e-03, -2.6291e-03,\n",
       "                      -3.6045e-02,  2.0099e-03, -2.3906e-03,  5.1034e-02, -6.3677e-02,\n",
       "                      -1.9784e-02, -3.3473e-02, -5.3215e-02, -3.8325e-02, -3.9259e-02,\n",
       "                      -6.1592e-02,  6.0429e-02, -3.4794e-02, -3.7627e-02,  3.6955e-02,\n",
       "                       4.7121e-02, -3.7519e-02, -5.5253e-03, -1.1038e-02, -7.6100e-03,\n",
       "                      -3.2377e-02,  1.4730e-02,  1.9119e-02, -1.0802e-02,  3.2543e-02,\n",
       "                      -5.1193e-04,  4.8707e-02, -6.6443e-02,  2.3717e-02, -4.3820e-02,\n",
       "                       3.8869e-02, -4.4347e-04, -4.0742e-02,  4.1572e-03, -3.4640e-02,\n",
       "                      -2.6115e-02, -4.3058e-02, -1.6150e-02, -2.5170e-02,  5.5192e-02,\n",
       "                       5.9949e-03, -1.3297e-02, -3.2203e-02,  5.5532e-02, -2.4934e-02,\n",
       "                       6.1811e-02, -3.7804e-02,  4.4809e-02, -4.8958e-02,  5.8155e-03,\n",
       "                      -1.7121e-02,  3.2363e-02, -1.1460e-02, -3.3455e-02, -1.9341e-02,\n",
       "                       5.0210e-02,  1.6693e-02,  4.5745e-02,  4.3577e-02, -2.1930e-02,\n",
       "                      -1.3312e-02,  7.2665e-04, -1.0379e-02, -2.6869e-02, -7.2166e-03,\n",
       "                      -5.5749e-02,  2.1331e-02, -7.3119e-04,  3.2344e-02,  1.8546e-02,\n",
       "                      -5.3060e-02, -3.5594e-02, -6.9314e-03, -5.2091e-02,  4.7009e-02,\n",
       "                      -3.6071e-02,  6.2957e-02,  2.5535e-02, -5.6998e-02, -3.2328e-02,\n",
       "                      -1.0317e-02, -1.8150e-02, -4.6760e-02, -4.4915e-02,  4.6313e-02,\n",
       "                       1.3409e-03,  4.3984e-02,  4.3185e-02,  1.6138e-02,  6.7888e-03,\n",
       "                      -3.5836e-02,  8.4774e-03,  1.8407e-02,  4.6534e-02, -3.5670e-02,\n",
       "                       1.1872e-02,  1.6512e-02, -3.9038e-02,  5.3598e-02,  3.0150e-02,\n",
       "                       3.0782e-02, -6.2381e-02,  4.6282e-02,  3.0928e-02, -6.0527e-02,\n",
       "                       4.0146e-03, -2.8261e-02, -2.1466e-02,  3.0694e-02,  2.4826e-02,\n",
       "                      -6.0297e-02, -2.9060e-02,  5.3880e-02, -5.2580e-02, -3.5457e-02,\n",
       "                       1.5521e-02,  2.6308e-02,  2.3698e-03,  2.8117e-02, -3.7257e-02,\n",
       "                       5.2717e-02, -6.2001e-02,  1.4971e-02, -4.5231e-02,  4.4396e-02,\n",
       "                       5.5803e-02, -1.7816e-02,  2.8169e-02,  5.7063e-02, -2.7185e-02,\n",
       "                      -2.3997e-02,  6.0608e-03, -9.3138e-03,  5.2615e-02,  3.0454e-02,\n",
       "                       2.4047e-02,  7.4602e-04, -5.8575e-02,  3.6571e-02, -7.6288e-03,\n",
       "                      -4.2865e-02, -2.8468e-02, -8.2386e-03, -3.5326e-02,  4.2688e-02,\n",
       "                      -5.4956e-02,  3.4149e-02, -4.1335e-02,  6.0408e-02, -3.4186e-02,\n",
       "                      -7.5690e-04,  6.4665e-02,  3.5585e-02,  3.9499e-02, -7.0247e-03,\n",
       "                       2.3252e-02,  2.7381e-02,  4.9036e-02,  2.7431e-02, -5.3896e-02,\n",
       "                       2.6850e-03,  5.7366e-02, -5.3679e-02], device='cuda:0')),\n",
       "             ('gru.bias_hh_l0',\n",
       "              tensor([ 3.5801e-03, -4.1052e-02,  5.6030e-03,  5.0461e-02,  2.0421e-02,\n",
       "                      -2.9303e-02,  1.3416e-02, -7.1503e-03,  2.8166e-02, -4.0906e-02,\n",
       "                       1.1662e-02,  3.8521e-03, -3.8541e-03,  1.0382e-02, -5.1072e-02,\n",
       "                      -4.3005e-02,  1.3710e-02, -5.7383e-02,  5.3789e-02,  4.6880e-02,\n",
       "                      -5.0215e-03, -8.6628e-03, -4.2774e-02,  4.7597e-02,  3.1589e-02,\n",
       "                       5.6119e-02,  2.3395e-04, -2.4301e-02,  2.5391e-03,  2.0486e-03,\n",
       "                       3.5787e-02, -1.9153e-02, -7.9048e-03,  5.0863e-02,  4.6967e-03,\n",
       "                       3.1759e-02, -2.9133e-02,  8.6584e-03, -4.1695e-02, -2.2774e-02,\n",
       "                      -9.3940e-03, -9.9071e-03,  2.6689e-02, -8.1822e-06, -3.6638e-03,\n",
       "                      -4.8458e-02,  2.0806e-02,  5.7257e-02, -2.7803e-02, -9.5944e-03,\n",
       "                      -1.5846e-02, -1.1400e-02, -2.7343e-02,  5.1837e-02,  5.1718e-02,\n",
       "                      -1.6275e-02, -1.6146e-02, -3.5363e-02, -1.6744e-02, -8.7096e-03,\n",
       "                      -1.8389e-02,  3.8237e-03,  1.8285e-02, -2.5825e-02,  1.0727e-02,\n",
       "                       1.9992e-02,  2.9383e-02,  5.4785e-02,  4.0813e-02, -6.2326e-02,\n",
       "                       2.1856e-02, -3.7717e-02,  4.2113e-02, -3.4126e-02, -7.4271e-03,\n",
       "                      -5.5510e-02,  4.0410e-02, -2.7260e-02,  1.4169e-02, -4.7821e-02,\n",
       "                       8.6632e-03, -6.3849e-03,  2.0199e-02,  5.5175e-02,  5.9930e-02,\n",
       "                       2.9193e-02,  4.2027e-02, -3.7448e-02, -2.5751e-02,  5.7535e-02,\n",
       "                      -3.8872e-02,  6.0279e-03, -4.6598e-02, -3.6308e-02, -1.7821e-02,\n",
       "                      -2.4887e-02, -4.5672e-02,  5.3283e-02,  2.4137e-02, -4.3982e-02,\n",
       "                      -2.6095e-02,  4.9559e-02, -5.4566e-02, -7.1931e-03, -3.8028e-02,\n",
       "                      -3.5407e-02,  5.3366e-02,  2.9874e-02, -6.1245e-02, -1.0211e-02,\n",
       "                      -2.9674e-02,  1.4372e-02,  6.6416e-05, -3.9575e-02,  1.8443e-03,\n",
       "                      -4.0753e-02, -4.6458e-02, -2.0601e-02,  5.8176e-02,  3.8261e-02,\n",
       "                       4.8550e-02, -2.6701e-03,  4.4000e-02, -3.1498e-02,  2.1678e-02,\n",
       "                      -4.4163e-02, -6.1999e-02,  4.6044e-02,  3.7189e-02, -8.0203e-03,\n",
       "                       2.3977e-02, -1.2251e-02, -4.4011e-02,  4.7148e-02, -5.6240e-02,\n",
       "                       1.2650e-02, -7.8647e-03, -4.5224e-02, -5.0131e-02, -3.1088e-02,\n",
       "                       4.1810e-02,  6.1427e-02, -5.8710e-02,  2.7391e-02,  3.4727e-02,\n",
       "                       3.1046e-02, -8.1600e-03,  5.8453e-02,  5.0958e-02, -3.6085e-02,\n",
       "                      -5.7740e-02, -4.1242e-02,  6.1700e-02, -4.3274e-02,  5.5181e-02,\n",
       "                      -5.7157e-02,  3.8149e-02, -4.7138e-02,  3.5162e-02,  1.9860e-02,\n",
       "                       3.6624e-02, -2.8802e-02,  2.7157e-02, -3.7643e-02,  1.1316e-02,\n",
       "                       5.2114e-02, -4.0483e-02, -3.1851e-03, -2.1559e-02,  1.8529e-02,\n",
       "                       4.2429e-02,  1.5676e-02, -3.4206e-02,  1.6375e-02,  2.0185e-02,\n",
       "                      -3.8370e-02, -6.1863e-02,  1.9696e-02, -1.2819e-02,  3.1058e-02,\n",
       "                      -1.7388e-02,  3.8446e-02,  3.5406e-02, -1.7739e-02, -5.8183e-02,\n",
       "                      -3.6449e-02,  3.5149e-02,  3.8909e-02,  6.2248e-02, -5.3642e-02,\n",
       "                       2.2092e-03,  5.7490e-02, -5.5539e-02,  8.6167e-03, -3.2877e-03,\n",
       "                       3.3527e-02,  2.8909e-02,  3.7123e-02,  5.9720e-02,  5.2011e-02,\n",
       "                       4.5737e-02, -3.6238e-02,  7.6068e-03,  8.6338e-04, -1.9583e-02,\n",
       "                       1.9056e-02,  5.4250e-03,  6.1370e-02,  5.3516e-02, -1.6872e-02,\n",
       "                      -1.0554e-02,  8.7882e-04, -5.5031e-02,  3.3175e-02, -3.5987e-02,\n",
       "                      -6.0714e-02,  3.2461e-02, -1.3116e-02, -3.5130e-02, -1.7952e-02,\n",
       "                      -4.6447e-02,  5.4952e-02, -3.6937e-02, -8.6798e-03, -6.1621e-02,\n",
       "                       8.7139e-03,  1.3060e-02, -5.4808e-02,  5.1411e-02,  4.8868e-02,\n",
       "                      -4.7368e-02,  2.5782e-02,  5.6732e-02, -4.7915e-02, -2.1662e-02,\n",
       "                      -1.6275e-02, -5.0097e-02, -3.2453e-02, -2.5855e-02, -1.2785e-02,\n",
       "                       9.9550e-03,  9.6931e-03,  7.6951e-04, -4.5408e-03,  7.5691e-03,\n",
       "                       1.1372e-04,  7.8456e-03,  6.1487e-03,  6.0550e-02,  1.3262e-03,\n",
       "                      -7.5161e-03,  3.9039e-02,  1.7936e-02,  3.1922e-02,  2.6122e-02,\n",
       "                      -5.3714e-03, -1.3418e-02, -1.4473e-02, -4.3959e-02, -5.8326e-02,\n",
       "                       2.6815e-02,  3.7697e-02, -5.6259e-02, -3.8058e-02, -5.6140e-02,\n",
       "                      -2.7913e-02,  2.4823e-02, -4.7902e-02, -5.7660e-02, -9.1229e-03,\n",
       "                       2.5207e-02, -4.9617e-02, -1.8789e-02, -1.7979e-02,  2.3407e-02,\n",
       "                       9.8823e-03, -5.3030e-02,  1.9608e-02,  4.1559e-02,  2.7155e-02,\n",
       "                       1.2470e-02, -4.1992e-02, -2.5802e-02, -4.6297e-02, -1.1682e-02,\n",
       "                       4.3619e-02,  5.7822e-02, -8.7563e-03, -6.0369e-02, -5.4588e-02,\n",
       "                      -1.5039e-02, -4.0055e-02, -5.4230e-02,  3.5764e-02,  1.1073e-02,\n",
       "                      -2.3431e-03,  4.6932e-02,  3.2872e-02, -4.7553e-02,  1.8975e-02,\n",
       "                       2.3216e-02,  3.1592e-02,  6.0583e-02, -6.2184e-02,  7.2425e-03,\n",
       "                       1.0415e-02, -5.3189e-02,  4.5005e-02,  5.2025e-02, -1.2199e-02,\n",
       "                      -1.9771e-02,  1.8892e-02,  1.7158e-02,  4.2721e-02, -3.7414e-02,\n",
       "                       2.3252e-02,  1.2473e-02,  6.0770e-02,  4.4167e-02,  1.9344e-03,\n",
       "                       1.6910e-02,  4.8615e-02, -1.8249e-02, -2.1261e-03,  2.0539e-02,\n",
       "                       4.7495e-02, -4.7634e-02, -5.8689e-02, -2.9090e-02, -3.1082e-02,\n",
       "                      -1.0274e-02,  3.1615e-02,  2.6456e-02, -9.8192e-03,  6.2751e-02,\n",
       "                      -5.4227e-02,  3.5077e-02, -4.2248e-02,  4.9610e-02,  4.7000e-02,\n",
       "                       2.4467e-02, -2.5178e-02,  4.5747e-02,  5.7617e-02, -4.0045e-02,\n",
       "                       1.0565e-02, -4.3887e-02, -1.9574e-02,  5.8505e-02, -2.8117e-02,\n",
       "                       1.1690e-02,  4.6203e-02,  1.5853e-02, -5.6718e-02, -1.6993e-02,\n",
       "                       5.5321e-02, -4.8500e-02, -6.5283e-04,  5.6354e-02,  9.3855e-03,\n",
       "                      -5.8688e-02, -2.6977e-02,  2.7867e-02,  3.2195e-02,  5.3002e-02,\n",
       "                      -5.2698e-02,  6.1054e-02, -5.6947e-02,  2.0232e-02, -6.0608e-02,\n",
       "                      -6.2738e-02, -5.1297e-02,  3.6108e-02, -3.9599e-02, -3.3373e-02,\n",
       "                      -4.8753e-02,  5.5666e-02,  5.9507e-03,  3.3461e-02, -4.9378e-02,\n",
       "                      -4.4003e-02, -4.2338e-02,  5.9035e-03, -4.4928e-02, -1.9239e-02,\n",
       "                       3.6168e-02, -4.4682e-02,  5.7865e-02, -4.0712e-02,  2.1464e-02,\n",
       "                      -3.1820e-02, -2.5446e-02, -2.3990e-02,  1.5444e-02,  5.1280e-02,\n",
       "                      -1.0198e-02,  1.4624e-02,  4.6680e-02,  8.5908e-03, -4.3313e-04,\n",
       "                       2.2558e-02,  1.3494e-02, -3.7129e-02, -8.2223e-03, -1.1995e-02,\n",
       "                      -6.6166e-03,  1.9197e-02, -5.6981e-02,  1.5493e-03, -1.9862e-02,\n",
       "                      -5.1983e-02,  3.4429e-02,  1.1263e-02, -6.0282e-02, -2.4619e-02,\n",
       "                       4.5046e-02, -1.0738e-02,  3.0455e-02, -5.5720e-02, -4.3158e-02,\n",
       "                      -3.2698e-02,  5.2932e-02,  3.7869e-02,  3.7952e-02, -1.0309e-03,\n",
       "                      -4.0964e-02,  6.0010e-02, -3.6352e-02, -4.8550e-02,  5.7778e-02,\n",
       "                      -9.5858e-03,  8.9621e-03,  4.9041e-02,  2.2122e-02,  4.1130e-02,\n",
       "                       5.8791e-02,  4.9868e-02, -6.1384e-02, -2.3226e-03,  7.8263e-03,\n",
       "                      -5.2790e-02,  5.4747e-02,  1.2282e-02,  2.9479e-02, -3.0433e-02,\n",
       "                      -3.1521e-02, -3.0546e-03, -3.3622e-03,  1.1191e-02, -4.2958e-02,\n",
       "                       6.0739e-02, -5.0129e-02,  1.7547e-02, -1.8253e-02, -5.9680e-02,\n",
       "                      -1.3725e-02,  1.5928e-02,  4.5801e-02,  2.3010e-02,  1.2576e-02,\n",
       "                      -3.6854e-02, -7.8213e-03,  4.8922e-02, -5.0616e-03,  4.1781e-02,\n",
       "                       3.0946e-02, -5.8394e-02,  5.9457e-02, -1.6107e-02, -2.9398e-02,\n",
       "                       5.0367e-03, -4.5687e-02,  2.1935e-02, -1.1746e-02, -3.5705e-02,\n",
       "                       4.8605e-03,  1.3280e-02, -2.2823e-02,  3.4652e-02,  1.1932e-02,\n",
       "                       3.0122e-02,  2.8924e-02,  5.3838e-02, -4.4432e-02,  4.5954e-02,\n",
       "                       4.9999e-02, -4.5979e-03,  4.3412e-02,  2.5122e-03, -1.4798e-02,\n",
       "                       2.7079e-02,  1.1599e-02,  2.5541e-02, -2.4532e-02, -2.5837e-02,\n",
       "                      -6.0435e-02,  8.4492e-03, -4.4048e-02, -4.4528e-02, -2.5733e-02,\n",
       "                       6.0958e-03, -2.6111e-02,  5.8685e-02,  4.0636e-02, -1.4345e-03,\n",
       "                       1.8858e-02, -1.5115e-02, -1.0399e-02, -7.2329e-03,  1.3453e-02,\n",
       "                       2.9119e-02,  1.5750e-02,  2.6289e-02, -5.7105e-02,  3.3058e-02,\n",
       "                       6.0272e-02,  5.5800e-02,  1.4816e-02,  4.6598e-02,  2.6605e-02,\n",
       "                       6.1095e-02, -4.9063e-02, -4.7878e-02, -4.4097e-02,  5.4016e-02,\n",
       "                       4.8305e-02, -3.5310e-02, -5.6122e-02,  2.5200e-02, -3.7001e-02,\n",
       "                      -5.4743e-02,  9.1459e-03, -4.5259e-02, -6.2818e-02, -5.0862e-02,\n",
       "                       9.6333e-03,  9.5176e-03, -3.6186e-02,  5.1065e-03,  3.2535e-02,\n",
       "                       3.1967e-02,  4.1953e-02,  4.8017e-02,  2.2642e-02,  1.1585e-02,\n",
       "                       4.8168e-02, -3.6983e-02,  5.3565e-03,  1.5741e-02, -4.5903e-02,\n",
       "                      -4.8845e-02, -5.5946e-02,  4.0227e-02,  1.6360e-02, -1.1572e-03,\n",
       "                      -3.1727e-02, -1.0146e-02,  5.3839e-02,  4.2450e-02,  3.5794e-02,\n",
       "                      -5.7408e-02,  1.2768e-02,  1.1831e-02, -3.3672e-02,  4.7132e-02,\n",
       "                      -5.0981e-02, -5.9573e-02,  4.9091e-02, -3.4408e-02,  3.0614e-02,\n",
       "                      -3.2043e-02,  2.2159e-02,  4.3739e-02, -2.8542e-02, -4.4979e-02,\n",
       "                      -3.8105e-02,  3.4424e-02, -1.1225e-02, -1.5175e-03, -9.0932e-03,\n",
       "                       1.2490e-02, -1.1519e-02, -2.9186e-02,  1.1547e-02,  3.7781e-02,\n",
       "                      -3.6206e-03, -6.2045e-02, -2.3698e-02,  2.4380e-02, -9.0667e-04,\n",
       "                      -4.9579e-03,  4.0299e-02, -1.5214e-03,  5.2358e-02, -5.7698e-02,\n",
       "                      -3.0859e-02,  4.9654e-02,  1.2015e-02,  8.2848e-03,  5.7152e-03,\n",
       "                       4.0809e-02,  2.9806e-02, -1.1159e-02, -2.4472e-02,  1.7040e-02,\n",
       "                      -4.5708e-02, -3.9251e-02, -9.9547e-03,  4.2463e-02,  1.4877e-02,\n",
       "                      -2.3757e-02,  1.3948e-03,  4.6687e-03,  1.9452e-02, -4.0518e-02,\n",
       "                       1.2457e-02,  4.2641e-02, -2.6083e-02, -4.8689e-02,  1.3122e-02,\n",
       "                      -2.9882e-02,  5.1685e-02,  2.5572e-02,  2.3057e-02,  2.5682e-02,\n",
       "                       4.7351e-02, -2.2863e-02,  1.1017e-02,  2.3943e-02,  3.1546e-02,\n",
       "                      -1.7262e-02,  5.8006e-02, -2.3933e-02,  2.2369e-02,  1.5775e-02,\n",
       "                      -2.0679e-02, -3.8945e-02,  2.0548e-02, -7.6420e-03,  3.6262e-02,\n",
       "                      -6.0045e-02, -1.7082e-02,  3.8008e-02, -2.6028e-02, -2.0659e-02,\n",
       "                      -3.7172e-02, -3.1514e-02,  3.0642e-02, -1.9565e-02, -4.3526e-02,\n",
       "                       6.1008e-02, -2.9980e-02, -6.6498e-03,  7.9564e-04, -5.7390e-02,\n",
       "                      -4.8708e-02, -3.0279e-02, -1.3846e-02,  4.3039e-02, -9.9226e-03,\n",
       "                      -1.7460e-02, -5.6151e-02, -4.1554e-02, -3.9035e-02,  1.1848e-02,\n",
       "                      -4.1332e-02, -8.0195e-03,  1.5749e-02, -3.7826e-02, -4.2677e-02,\n",
       "                       2.5957e-02,  1.2433e-02, -2.3378e-02, -4.5873e-02, -1.0709e-02,\n",
       "                      -9.2809e-03,  4.7552e-02,  5.8709e-02, -2.8127e-02, -3.2766e-02,\n",
       "                      -4.2600e-02,  3.4026e-02, -4.5954e-02,  4.9262e-02, -3.7916e-02,\n",
       "                      -3.7800e-02,  3.4268e-02,  4.8099e-02,  4.0564e-02, -2.9545e-02,\n",
       "                       5.4429e-02,  4.3378e-02, -1.4253e-02,  1.3059e-02,  1.3050e-02,\n",
       "                       2.9780e-02, -6.0265e-02, -4.6824e-02, -2.5462e-02, -4.5603e-02,\n",
       "                       4.1013e-02, -1.7014e-02, -5.1103e-03,  5.4774e-02, -1.4809e-02,\n",
       "                      -8.8937e-03, -1.0300e-02, -1.9040e-03,  2.8109e-02, -5.5607e-03,\n",
       "                       6.1429e-02,  2.7777e-02,  4.6351e-02, -5.2498e-02,  7.7036e-03,\n",
       "                      -2.3911e-02,  3.1225e-02, -5.7500e-03,  2.5779e-02, -5.1385e-02,\n",
       "                      -3.4554e-02, -2.4390e-02, -1.8838e-02, -1.2267e-02,  3.5928e-02,\n",
       "                      -5.3249e-02,  5.8855e-02,  1.4176e-02, -5.2279e-02, -4.6492e-02,\n",
       "                       4.7943e-02,  6.2278e-02,  3.4267e-02,  2.6634e-02, -1.8603e-02,\n",
       "                      -2.1922e-02,  5.4707e-02,  5.1496e-02, -1.7978e-02,  5.0533e-02,\n",
       "                      -4.7782e-02, -5.7200e-02,  3.4472e-02, -1.2908e-02,  5.4748e-02,\n",
       "                      -2.9738e-02,  5.3764e-02,  6.1968e-02,  2.9068e-02, -3.6613e-02,\n",
       "                      -3.3707e-02, -1.4943e-03, -2.2634e-02, -1.3803e-02, -3.2326e-02,\n",
       "                       5.5980e-03,  4.0439e-02, -4.1973e-02,  2.6513e-02,  4.4434e-04,\n",
       "                       2.9083e-02, -3.3954e-02, -2.0837e-02,  1.9958e-02, -4.2821e-02,\n",
       "                       1.9444e-02,  4.4311e-02, -4.8385e-02], device='cuda:0'))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder1.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
